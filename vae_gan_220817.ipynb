{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.7.10",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "colab": {
      "name": "vae-gan_220817.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/minwoongPark/TEST/blob/main/vae_gan_220817.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow_addons"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_2wGNNxCT-op",
        "outputId": "8c541777-be74-4b07-8377-a34b28567288"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting tensorflow_addons\n",
            "  Downloading tensorflow_addons-0.17.1-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1 MB 4.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from tensorflow_addons) (21.3)\n",
            "Requirement already satisfied: typeguard>=2.7 in /usr/local/lib/python3.7/dist-packages (from tensorflow_addons) (2.7.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->tensorflow_addons) (3.0.9)\n",
            "Installing collected packages: tensorflow-addons\n",
            "Successfully installed tensorflow-addons-0.17.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "import tensorflow.keras as keras\n",
        "import keras.layers as layers\n",
        "from sklearn.model_selection import train_test_split\n",
        "import random\n",
        "import tensorflow_probability as tfp\n",
        "import tensorflow_addons as tfa"
      ],
      "metadata": {
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "_kg_hide-input": true,
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "papermill": {
          "duration": 7.251715,
          "end_time": "2021-11-08T23:15:36.075922",
          "exception": false,
          "start_time": "2021-11-08T23:15:28.824207",
          "status": "completed"
        },
        "tags": [],
        "execution": {
          "iopub.status.busy": "2022-08-17T05:33:16.970779Z",
          "iopub.execute_input": "2022-08-17T05:33:16.971228Z",
          "iopub.status.idle": "2022-08-17T05:33:16.977587Z",
          "shell.execute_reply.started": "2022-08-17T05:33:16.971193Z",
          "shell.execute_reply": "2022-08-17T05:33:16.976814Z"
        },
        "trusted": true,
        "id": "T2HWFR26T5ei"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oyvirfs6We9P",
        "outputId": "d3f7d5a2-7a08-426e-b878-752f4fafb15f"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Data Augmentation**"
      ],
      "metadata": {
        "papermill": {
          "duration": 0.0133,
          "end_time": "2021-11-08T23:15:36.104095",
          "exception": false,
          "start_time": "2021-11-08T23:15:36.090795",
          "status": "completed"
        },
        "tags": [],
        "id": "VQ1TAY0pT5el"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing import image_dataset_from_directory\n",
        "from keras import backend as K\n",
        "\n",
        "batch_size= 24\n",
        "image_size = [128, 128]\n",
        "\n",
        "\n",
        "ds = image_dataset_from_directory(\n",
        "    '/content/drive/MyDrive/transistor/train',\n",
        "    labels=None,\n",
        "    image_size=image_size,\n",
        "    interpolation='nearest',\n",
        "    batch_size=batch_size,\n",
        "    shuffle=True,\n",
        ")\n",
        "\n",
        "def convert_to_float(image):\n",
        "    image = tf.image.convert_image_dtype(image, dtype=tf.float32)\n",
        "    return image\n",
        "\n",
        "\n",
        "def trans1(img):\n",
        "    return tfa.image.rotate(tf.image.flip_left_right(tf.image.flip_up_down(img)),-.2,fill_mode=\"reflect\",interpolation=\"bilinear\")\n",
        "\n",
        "def trans2(img):\n",
        "    return tfa.image.rotate(img,-.2,fill_mode=\"reflect\",interpolation=\"bilinear\")\n",
        "\n",
        "def trans3(img):\n",
        "    return tfa.image.rotate(img,.2,fill_mode=\"reflect\",interpolation=\"bilinear\")\n",
        "    \n",
        "ds1,ds2,ds3,ds4 = ds,ds.map(trans1),ds.map(trans2),ds.map(trans3)\n",
        "\n",
        "ds = ds1.concatenate(ds2).concatenate(ds3).concatenate(ds4)\n",
        "\n",
        "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
        "ds = (\n",
        "    ds\n",
        "    .map(convert_to_float)\n",
        "    .cache()\n",
        "    .prefetch(buffer_size=AUTOTUNE)\n",
        ")"
      ],
      "metadata": {
        "_kg_hide-output": true,
        "papermill": {
          "duration": 3.787245,
          "end_time": "2021-11-08T23:15:39.905273",
          "exception": false,
          "start_time": "2021-11-08T23:15:36.118028",
          "status": "completed"
        },
        "tags": [],
        "execution": {
          "iopub.status.busy": "2022-08-17T05:33:16.983560Z",
          "iopub.execute_input": "2022-08-17T05:33:16.985163Z",
          "iopub.status.idle": "2022-08-17T05:33:17.410895Z",
          "shell.execute_reply.started": "2022-08-17T05:33:16.985131Z",
          "shell.execute_reply": "2022-08-17T05:33:17.410034Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LS1tCaKaT5em",
        "outputId": "126949bc-1e66-4dd9-df10-e4c16ee3ab6e"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 213 files belonging to 1 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ds_a = image_dataset_from_directory(\n",
        "    '/content/drive/MyDrive/transistor/test/damaged_case',\n",
        "    labels=None,\n",
        "    image_size=image_size,\n",
        "    interpolation='nearest',\n",
        "    batch_size=batch_size,\n",
        "    shuffle=True,\n",
        ")\n",
        "print(type(ds))\n",
        "\n",
        "def convert_to_float(image):\n",
        "    image = tf.image.convert_image_dtype(image, dtype=tf.float32)\n",
        "    return image\n",
        "\n",
        "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
        "ds_a = (\n",
        "    ds_a\n",
        "    .map(convert_to_float)\n",
        "    .cache()\n",
        "    .prefetch(buffer_size=AUTOTUNE)\n",
        ")"
      ],
      "metadata": {
        "papermill": {
          "duration": 0.169498,
          "end_time": "2021-11-08T23:15:40.089551",
          "exception": false,
          "start_time": "2021-11-08T23:15:39.920053",
          "status": "completed"
        },
        "tags": [],
        "execution": {
          "iopub.status.busy": "2022-08-17T05:33:17.412777Z",
          "iopub.execute_input": "2022-08-17T05:33:17.413067Z",
          "iopub.status.idle": "2022-08-17T05:33:17.577037Z",
          "shell.execute_reply.started": "2022-08-17T05:33:17.413029Z",
          "shell.execute_reply": "2022-08-17T05:33:17.575142Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sA-akxeiT5en",
        "outputId": "a9701164-bd62-4198-b42d-c4ab1bd98aa6"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 10 files belonging to 1 classes.\n",
            "<class 'tensorflow.python.data.ops.dataset_ops.PrefetchDataset'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Making my model**"
      ],
      "metadata": {
        "papermill": {
          "duration": 0.013674,
          "end_time": "2021-11-08T23:15:40.117706",
          "exception": false,
          "start_time": "2021-11-08T23:15:40.104032",
          "status": "completed"
        },
        "tags": [],
        "id": "sAsAeWpwT5eo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Sampling(layers.Layer):\n",
        "    \"\"\"Uses (z_mean, z_log_var) to sample z, the vector encoding a digit.\"\"\"\n",
        "\n",
        "    def call(self, inputs):\n",
        "        z_mean, z_log_var = inputs\n",
        "        batch = tf.shape(z_mean)[0]\n",
        "        dim = tf.shape(z_mean)[1]\n",
        "        epsilon = tf.keras.backend.random_normal(shape=(batch, dim))\n",
        "        return z_mean + tf.exp(0.5 * z_log_var) * epsilon"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-08-17T05:33:17.578586Z",
          "iopub.execute_input": "2022-08-17T05:33:17.578850Z",
          "iopub.status.idle": "2022-08-17T05:33:17.585210Z",
          "shell.execute_reply.started": "2022-08-17T05:33:17.578813Z",
          "shell.execute_reply": "2022-08-17T05:33:17.584287Z"
        },
        "trusted": true,
        "id": "5tBz5gu1T5eo"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lrelu = tf.nn.selu"
      ],
      "metadata": {
        "papermill": {
          "duration": 0.020013,
          "end_time": "2021-11-08T23:15:40.151693",
          "exception": false,
          "start_time": "2021-11-08T23:15:40.13168",
          "status": "completed"
        },
        "tags": [],
        "execution": {
          "iopub.status.busy": "2022-08-17T05:33:17.588039Z",
          "iopub.execute_input": "2022-08-17T05:33:17.588717Z",
          "iopub.status.idle": "2022-08-17T05:33:17.595462Z",
          "shell.execute_reply.started": "2022-08-17T05:33:17.588675Z",
          "shell.execute_reply": "2022-08-17T05:33:17.594514Z"
        },
        "trusted": true,
        "id": "SyiPcjR_T5ep"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "latent_dim = 128\n",
        "a,b = image_size\n",
        "shape=(a, b,3)\n",
        "\n",
        "\n",
        "encoder_inputs = keras.Input(shape=shape)\n",
        "x = layers.Conv2D(32, 3, activation=\"relu\", strides=2, padding=\"same\")(encoder_inputs)\n",
        "x = layers.BatchNormalization()(x)\n",
        "x = layers.Conv2D(64, 3, activation=\"relu\", strides=2, padding=\"same\")(x)\n",
        "x = layers.BatchNormalization()(x)\n",
        "x = layers.Conv2D(128, 3, activation=\"relu\", strides=2, padding=\"same\")(x)\n",
        "x = layers.BatchNormalization()(x)\n",
        "x = layers.Conv2D(256, 3, activation=\"relu\", strides=2, padding=\"same\")(x)\n",
        "x = layers.Flatten()(x)\n",
        "x = layers.Dense(160, activation=\"tanh\")(x)\n",
        "z_mean = layers.Dense(latent_dim, name=\"z_mean\")(x)\n",
        "z_log_var = layers.Dense(latent_dim, name=\"z_log_var\")(x)\n",
        "z = Sampling()([z_mean, z_log_var])\n",
        "encoder = keras.Model(encoder_inputs, [z_mean, z_log_var, z], name=\"encoder\")\n",
        "encoder.summary()"
      ],
      "metadata": {
        "_kg_hide-output": true,
        "papermill": {
          "duration": 0.27431,
          "end_time": "2021-11-08T23:15:40.440843",
          "exception": false,
          "start_time": "2021-11-08T23:15:40.166533",
          "status": "completed"
        },
        "tags": [],
        "execution": {
          "iopub.status.busy": "2022-08-17T05:33:17.597453Z",
          "iopub.execute_input": "2022-08-17T05:33:17.597645Z",
          "iopub.status.idle": "2022-08-17T05:33:17.724030Z",
          "shell.execute_reply.started": "2022-08-17T05:33:17.597620Z",
          "shell.execute_reply": "2022-08-17T05:33:17.723269Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YULmrlUZT5eq",
        "outputId": "b33c7471-05c1-4cb1-e264-ff8ceadf62a1"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"encoder\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)           [(None, 128, 128, 3  0           []                               \n",
            "                                )]                                                                \n",
            "                                                                                                  \n",
            " conv2d (Conv2D)                (None, 64, 64, 32)   896         ['input_1[0][0]']                \n",
            "                                                                                                  \n",
            " batch_normalization (BatchNorm  (None, 64, 64, 32)  128         ['conv2d[0][0]']                 \n",
            " alization)                                                                                       \n",
            "                                                                                                  \n",
            " conv2d_1 (Conv2D)              (None, 32, 32, 64)   18496       ['batch_normalization[0][0]']    \n",
            "                                                                                                  \n",
            " batch_normalization_1 (BatchNo  (None, 32, 32, 64)  256         ['conv2d_1[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv2d_2 (Conv2D)              (None, 16, 16, 128)  73856       ['batch_normalization_1[0][0]']  \n",
            "                                                                                                  \n",
            " batch_normalization_2 (BatchNo  (None, 16, 16, 128)  512        ['conv2d_2[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv2d_3 (Conv2D)              (None, 8, 8, 256)    295168      ['batch_normalization_2[0][0]']  \n",
            "                                                                                                  \n",
            " flatten (Flatten)              (None, 16384)        0           ['conv2d_3[0][0]']               \n",
            "                                                                                                  \n",
            " dense (Dense)                  (None, 160)          2621600     ['flatten[0][0]']                \n",
            "                                                                                                  \n",
            " z_mean (Dense)                 (None, 128)          20608       ['dense[0][0]']                  \n",
            "                                                                                                  \n",
            " z_log_var (Dense)              (None, 128)          20608       ['dense[0][0]']                  \n",
            "                                                                                                  \n",
            " sampling (Sampling)            (None, 128)          0           ['z_mean[0][0]',                 \n",
            "                                                                  'z_log_var[0][0]']              \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 3,052,128\n",
            "Trainable params: 3,051,680\n",
            "Non-trainable params: 448\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "latent_inputs = keras.Input(shape=(latent_dim,))\n",
        "x = layers.Dense(8* 8 * 64, activation=\"relu\")(latent_inputs)\n",
        "x = layers.Reshape((8, 8, 64))(x)\n",
        "x = layers.Conv2DTranspose(256, 2, activation=\"relu\", strides=2, padding=\"same\")(x)\n",
        "x = layers.Conv2D(256, 3, activation=\"relu\", strides=1, padding=\"same\")(x)\n",
        "x = layers.BatchNormalization()(x)\n",
        "x = layers.Conv2DTranspose(128, 2, activation=\"relu\", strides=2, padding=\"same\")(x)\n",
        "x = layers.Conv2D(128, 3, activation=\"relu\", strides=1, padding=\"same\")(x)\n",
        "x = layers.BatchNormalization()(x)\n",
        "x = layers.Conv2DTranspose(64, 2, activation=\"relu\", strides=2, padding=\"same\")(x)\n",
        "x = layers.Conv2D(64, 3, activation=\"relu\", strides=1, padding=\"same\")(x)\n",
        "x = layers.BatchNormalization()(x)\n",
        "x = layers.Conv2DTranspose(32, 2, activation=\"relu\", strides=2, padding=\"same\")(x)\n",
        "x = layers.Conv2D(32, 3, activation=\"relu\", strides=1, padding=\"same\")(x)\n",
        "decoder_outputs = layers.Conv2DTranspose(3, 3, activation=\"sigmoid\", padding=\"same\")(x)\n",
        "decoder = keras.Model(latent_inputs, decoder_outputs, name=\"decoder\")\n",
        "decoder.summary()"
      ],
      "metadata": {
        "papermill": {
          "duration": 0.023852,
          "end_time": "2021-11-08T23:15:40.479361",
          "exception": false,
          "start_time": "2021-11-08T23:15:40.455509",
          "status": "completed"
        },
        "tags": [],
        "execution": {
          "iopub.status.busy": "2022-08-17T05:33:17.725849Z",
          "iopub.execute_input": "2022-08-17T05:33:17.726170Z",
          "iopub.status.idle": "2022-08-17T05:33:17.896901Z",
          "shell.execute_reply.started": "2022-08-17T05:33:17.726133Z",
          "shell.execute_reply": "2022-08-17T05:33:17.894053Z"
        },
        "trusted": true,
        "id": "lsvZmWuJT5eq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "discriminator_inputs = keras.Input(shape=shape)\n",
        "\n",
        "x = layers.Conv2D(128, 8, activation=\"relu\", strides=2, padding=\"same\")(discriminator_inputs)\n",
        "x = layers.MaxPool2D()(x)\n",
        "x = layers.BatchNormalization()(x)\n",
        "x = layers.Conv2D(64, 5, activation=\"relu\", strides=2, padding=\"same\")(x)\n",
        "x = layers.MaxPool2D()(x)\n",
        "x = layers.BatchNormalization()(x)\n",
        "x = layers.Conv2D(32, 4, activation=\"relu\", strides=2, padding=\"same\")(x)\n",
        "x = layers.Flatten()(x)\n",
        "x = layers.Dense(32, activation=\"relu\")(x)\n",
        "discriminator_outputs = layers.Dense(1,activation=\"sigmoid\")(x)\n",
        "discriminator = keras.Model(discriminator_inputs, discriminator_outputs, name=\"discriminator\")\n",
        "discriminator.summary()"
      ],
      "metadata": {
        "_kg_hide-output": true,
        "papermill": {
          "duration": 0.120348,
          "end_time": "2021-11-08T23:15:40.614218",
          "exception": false,
          "start_time": "2021-11-08T23:15:40.49387",
          "status": "completed"
        },
        "tags": [],
        "execution": {
          "iopub.status.busy": "2022-08-17T05:33:17.898773Z",
          "iopub.execute_input": "2022-08-17T05:33:17.899098Z",
          "iopub.status.idle": "2022-08-17T05:33:17.984502Z",
          "shell.execute_reply.started": "2022-08-17T05:33:17.899060Z",
          "shell.execute_reply": "2022-08-17T05:33:17.983612Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gbmY9Q3_T5er",
        "outputId": "ad2ba30a-bf02-478b-e799-c68dfc7fb70d"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"discriminator\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_3 (InputLayer)        [(None, 128, 128, 3)]     0         \n",
            "                                                                 \n",
            " conv2d_8 (Conv2D)           (None, 64, 64, 128)       24704     \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2D  (None, 32, 32, 128)      0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " batch_normalization_6 (Batc  (None, 32, 32, 128)      512       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " conv2d_9 (Conv2D)           (None, 16, 16, 64)        204864    \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPooling  (None, 8, 8, 64)         0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " batch_normalization_7 (Batc  (None, 8, 8, 64)         256       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " conv2d_10 (Conv2D)          (None, 4, 4, 32)          32800     \n",
            "                                                                 \n",
            " flatten_1 (Flatten)         (None, 512)               0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 32)                16416     \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 1)                 33        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 279,585\n",
            "Trainable params: 279,201\n",
            "Non-trainable params: 384\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def corr_loss(z):\n",
        "    coor_matrix = tfp.stats.correlation(z)\n",
        "    loss = 0\n",
        "    n,m = coor_matrix.shape\n",
        "    for i in range(n):\n",
        "        for j in range(m):\n",
        "            if i!=j:\n",
        "                loss+=coor_matrix[i,j]**2\n",
        "    return loss"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-08-17T05:33:17.985678Z",
          "iopub.execute_input": "2022-08-17T05:33:17.987024Z",
          "iopub.status.idle": "2022-08-17T05:33:17.995629Z",
          "shell.execute_reply.started": "2022-08-17T05:33:17.986978Z",
          "shell.execute_reply": "2022-08-17T05:33:17.994663Z"
        },
        "trusted": true,
        "id": "Dt-UbSL2T5er"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class VAE(keras.Model):\n",
        "    def __init__(self, encoder, decoder, **kwargs):\n",
        "        super(VAE, self).__init__(**kwargs)\n",
        "        self.encoder = encoder\n",
        "        self.decoder = decoder\n",
        "        self.total_loss_tracker = keras.metrics.Mean(name=\"total_loss\")\n",
        "        self.reconstruction_loss_tracker = keras.metrics.Mean(\n",
        "            name=\"reconstruction_loss\"\n",
        "        )\n",
        "        self.kl_loss_tracker = keras.metrics.Mean(name=\"kl_loss\")\n",
        "        \n",
        "        \n",
        "    def call(self,x):\n",
        "        z_mean, z_log_var, z = self.encoder(x)\n",
        "        reconstruction = self.decoder(z)\n",
        "        return z,reconstruction\n",
        "\n",
        "    \n",
        "    @property\n",
        "    def metrics(self):\n",
        "        return [\n",
        "            self.total_loss_tracker,\n",
        "            self.reconstruction_loss_tracker,\n",
        "            self.kl_loss_tracker,\n",
        "        ]\n",
        "\n",
        "    def train_step(self, data):\n",
        "        with tf.GradientTape() as tape:\n",
        "            z_mean, z_log_var, z = self.encoder(data)\n",
        "            reconstruction = self.decoder(z)\n",
        "            reconstruction_loss = tf.reduce_mean(\n",
        "            tf.reduce_sum(keras.losses.binary_crossentropy(data, reconstruction), axis=(1, 2)))\n",
        "            kl_loss = -0.5 * (1 + z_log_var - tf.square(z_mean) - tf.exp(z_log_var))\n",
        "            kl_loss = tf.reduce_mean(tf.reduce_sum(kl_loss, axis=1))\n",
        "            #coorelation_loss = corr_loss(z)\n",
        "            \n",
        "            total_loss = reconstruction_loss + kl_loss\n",
        "        grads = tape.gradient(total_loss, self.trainable_weights)\n",
        "        self.optimizer.apply_gradients(zip(grads, self.trainable_weights))\n",
        "        self.total_loss_tracker.update_state(total_loss)\n",
        "        self.reconstruction_loss_tracker.update_state(reconstruction_loss)\n",
        "        self.kl_loss_tracker.update_state(kl_loss)\n",
        "        return {\n",
        "            \"loss\": self.total_loss_tracker.result(),\n",
        "            \"reconstruction_loss\": self.reconstruction_loss_tracker.result(),\n",
        "            \"kl_loss\": self.kl_loss_tracker.result(),\n",
        "        }"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-08-17T05:33:17.997505Z",
          "iopub.execute_input": "2022-08-17T05:33:17.997852Z",
          "iopub.status.idle": "2022-08-17T05:33:18.011107Z",
          "shell.execute_reply.started": "2022-08-17T05:33:17.997781Z",
          "shell.execute_reply": "2022-08-17T05:33:18.010150Z"
        },
        "trusted": true,
        "id": "bwyQBeJlT5es"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras import backend as K\n",
        "class VAE_GAN(keras.Model):    \n",
        "\n",
        "    def __init__(self, vae, discriminator, opti1=keras.optimizers.Adam(), opti2=keras.optimizers.Adam(), opti3=keras.optimizers.Adam(), **kwargs):\n",
        "        super(VAE_GAN, self).__init__(**kwargs)\n",
        "        \n",
        "        self.encoder = vae.encoder\n",
        "        self.decoder = vae.decoder\n",
        "        self.discriminator = discriminator\n",
        "        self.vae = vae\n",
        "        \n",
        "        self.vae_loss_tracker = keras.metrics.Mean(name=\"total_loss\")\n",
        "        self.reconstruction_loss_tracker = keras.metrics.Mean(name=\"reconstruction_loss\")\n",
        "        self.kl_loss_tracker = keras.metrics.Mean(name=\"kl_loss\")\n",
        "        self.correlation_loss_tracker = keras.metrics.Mean(name=\"cr_loss\")\n",
        "        self.disc_loss_tracker = keras.metrics.Mean(name=\"disc_loss\")\n",
        "        self.gen_loss_tracker = keras.metrics.Mean(name=\"gen_loss\")\n",
        "        self.disc_loss = keras.losses.BinaryCrossentropy()\n",
        "        \n",
        "        self.vae_optimizer = opti1\n",
        "        self.gen_optimizer = opti2\n",
        "        self.disc_optimizer = opti3\n",
        "        \n",
        "    def call(self,x):\n",
        "        z_mean, z_log_var, z = self.encoder(x)\n",
        "        reconstruction = self.decoder(z)\n",
        "        return z,reconstruction\n",
        "\n",
        "    @property\n",
        "    def metrics(self):\n",
        "        return [\n",
        "            self.vae_loss_tracker,\n",
        "            self.reconstruction_loss_tracker,\n",
        "            self.kl_loss_tracker,\n",
        "            self.correlation_loss_tracker,\n",
        "            self.disc_loss_tracker,\n",
        "            self.gen_loss_tracker\n",
        "        ]\n",
        "\n",
        "    def train_step(self, data):        \n",
        "        batch_size = K.shape(data)[0]    \n",
        "        \n",
        "        with tf.GradientTape() as enc_tape, tf.GradientTape() as dec_tape, tf.GradientTape() as disc_tape:\n",
        "            \n",
        "            z_mean, z_log_var, z = self.encoder(data)\n",
        "            \n",
        "            reconstruction = self.decoder(z)\n",
        "            \n",
        "            reconstruction_loss = tf.reduce_mean(\n",
        "            tf.reduce_sum(keras.losses.binary_crossentropy(data, reconstruction), axis=(1, 2)))\n",
        "            kl_loss = -0.5 * (1 + z_log_var - tf.square(z_mean) - tf.exp(z_log_var))\n",
        "            kl_loss = tf.reduce_mean(tf.reduce_sum(kl_loss, axis=1))\n",
        "            coorelation_loss = corr_loss(z)\n",
        "            \n",
        "            \n",
        "            # GAN\n",
        "            #batch_size = 12\n",
        "            recon_vect = z#tf.random.normal((batch_size, latent_dim))\n",
        "            contruction = self.decoder(recon_vect)\n",
        "            combined_images = tf.concat([data, contruction], axis=0)\n",
        "            data_l,recon_l = tf.zeros((batch_size, 1)),tf.ones((batch_size, 1))\n",
        "            combined_l = tf.concat([data_l, recon_l], axis=0)\n",
        "            tot_predictions = self.discriminator(combined_images)\n",
        "            r_prediction = self.discriminator(contruction)\n",
        "\n",
        "            discr_loss = self.disc_loss(combined_l,tot_predictions)\n",
        "            #fake labels : \n",
        "            #gen_loss =  self.disc_loss(recon_l,r_prediction)\n",
        "            gen_loss = tf.math.maximum(self.disc_loss(data_l,r_prediction) - discr_loss,.0001)\n",
        "        \n",
        "            #=========\n",
        "            vae_loss = reconstruction_loss + kl_loss + gen_loss #+.1*coorelation_loss \n",
        "\n",
        "               \n",
        "        grad_discr = disc_tape.gradient(discr_loss, self.discriminator.trainable_weights)\n",
        "        grad_vae = enc_tape.gradient(vae_loss, self.vae.trainable_weights)\n",
        "        #grad_gen = dec_tape.gradient(gen_loss, self.decoder.trainable_weights)\n",
        "        \n",
        "        \n",
        "        #self.gen_optimizer.apply_gradients(zip(grad_gen, self.decoder.trainable_weights))\n",
        "        self.disc_optimizer.apply_gradients(zip(grad_discr, self.discriminator.trainable_weights))\n",
        "        self.vae_optimizer.apply_gradients(zip(grad_vae, self.vae.trainable_weights))\n",
        "\n",
        "                                           \n",
        "        self.vae_loss_tracker.update_state(vae_loss)\n",
        "        self.reconstruction_loss_tracker.update_state(reconstruction_loss)\n",
        "        self.kl_loss_tracker.update_state(kl_loss)\n",
        "        self.correlation_loss_tracker.update_state(coorelation_loss)\n",
        "        self.disc_loss_tracker.update_state(discr_loss)\n",
        "        self.gen_loss_tracker.update_state(gen_loss)\n",
        "        \n",
        "        return {\n",
        "            \"vae_loss\": self.vae_loss_tracker.result(),\n",
        "            \"disc_loss\": self.disc_loss_tracker.result(),\n",
        "            \"gen_los\": self.gen_loss_tracker.result(),\n",
        "        }"
      ],
      "metadata": {
        "papermill": {
          "duration": 0.027931,
          "end_time": "2021-11-08T23:15:40.657783",
          "exception": false,
          "start_time": "2021-11-08T23:15:40.629852",
          "status": "completed"
        },
        "tags": [],
        "execution": {
          "iopub.status.busy": "2022-08-17T05:33:18.015812Z",
          "iopub.execute_input": "2022-08-17T05:33:18.016599Z",
          "iopub.status.idle": "2022-08-17T05:33:18.040667Z",
          "shell.execute_reply.started": "2022-08-17T05:33:18.016476Z",
          "shell.execute_reply": "2022-08-17T05:33:18.039781Z"
        },
        "trusted": true,
        "id": "T-0HyJOfT5es"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Training**"
      ],
      "metadata": {
        "papermill": {
          "duration": 0.01532,
          "end_time": "2021-11-08T23:15:40.688781",
          "exception": false,
          "start_time": "2021-11-08T23:15:40.673461",
          "status": "completed"
        },
        "tags": [],
        "id": "GO3K4YerT5et"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vae = VAE(encoder,decoder)\n",
        "model = VAE_GAN(vae, discriminator)\n",
        "model.compile(optimizer=keras.optimizers.Adam())"
      ],
      "metadata": {
        "papermill": {
          "duration": 0.042951,
          "end_time": "2021-11-08T23:15:40.783361",
          "exception": false,
          "start_time": "2021-11-08T23:15:40.74041",
          "status": "completed"
        },
        "tags": [],
        "execution": {
          "iopub.status.busy": "2022-08-17T05:33:18.042015Z",
          "iopub.execute_input": "2022-08-17T05:33:18.042720Z",
          "iopub.status.idle": "2022-08-17T05:33:18.094061Z",
          "shell.execute_reply.started": "2022-08-17T05:33:18.042684Z",
          "shell.execute_reply": "2022-08-17T05:33:18.093268Z"
        },
        "trusted": true,
        "id": "_pQsFE49T5et"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(ds, epochs=500,verbose=1)"
      ],
      "metadata": {
        "_kg_hide-output": true,
        "papermill": {
          "duration": 292.589834,
          "end_time": "2021-11-08T23:20:33.388656",
          "exception": false,
          "start_time": "2021-11-08T23:15:40.798822",
          "status": "completed"
        },
        "tags": [],
        "execution": {
          "iopub.status.busy": "2022-08-17T05:33:18.095743Z",
          "iopub.execute_input": "2022-08-17T05:33:18.096180Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zdh_3cZlT5et",
        "outputId": "2d6e31d0-11c4-4bdf-8ec1-8aca136e2c41"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/500\n",
            "36/36 [==============================] - 305s 823ms/step - vae_loss: 10824.5611 - disc_loss: 0.4412 - gen_los: 0.5887\n",
            "Epoch 2/500\n",
            "36/36 [==============================] - 11s 292ms/step - vae_loss: 9713.2715 - disc_loss: 0.1458 - gen_los: 2.4211\n",
            "Epoch 3/500\n",
            "36/36 [==============================] - 11s 293ms/step - vae_loss: 9688.0282 - disc_loss: 0.0031 - gen_los: 5.7182\n",
            "Epoch 4/500\n",
            "36/36 [==============================] - 11s 293ms/step - vae_loss: 9669.3627 - disc_loss: 0.0032 - gen_los: 6.2909\n",
            "Epoch 5/500\n",
            "36/36 [==============================] - 11s 296ms/step - vae_loss: 9623.2145 - disc_loss: 0.0375 - gen_los: 6.1970\n",
            "Epoch 6/500\n",
            "36/36 [==============================] - 11s 294ms/step - vae_loss: 9592.2792 - disc_loss: 0.0011 - gen_los: 6.3215\n",
            "Epoch 7/500\n",
            "36/36 [==============================] - 11s 297ms/step - vae_loss: 9616.5345 - disc_loss: 9.1557e-05 - gen_los: 9.2104\n",
            "Epoch 8/500\n",
            "36/36 [==============================] - 11s 296ms/step - vae_loss: 9593.4770 - disc_loss: 6.1440e-05 - gen_los: 9.6597\n",
            "Epoch 9/500\n",
            "36/36 [==============================] - 11s 295ms/step - vae_loss: 9596.9586 - disc_loss: 6.5920e-05 - gen_los: 9.9113\n",
            "Epoch 10/500\n",
            "36/36 [==============================] - 11s 297ms/step - vae_loss: 9609.6845 - disc_loss: 6.4742e-05 - gen_los: 10.2225\n",
            "Epoch 11/500\n",
            "36/36 [==============================] - 11s 296ms/step - vae_loss: 9612.6153 - disc_loss: 2.5560e-05 - gen_los: 10.7782\n",
            "Epoch 12/500\n",
            "36/36 [==============================] - 11s 297ms/step - vae_loss: 9584.7745 - disc_loss: 3.2187e-05 - gen_los: 10.5835\n",
            "Epoch 13/500\n",
            "36/36 [==============================] - 11s 296ms/step - vae_loss: 9569.7098 - disc_loss: 2.6791e-05 - gen_los: 11.0157\n",
            "Epoch 14/500\n",
            "36/36 [==============================] - 11s 297ms/step - vae_loss: 9569.7492 - disc_loss: 5.6025e-05 - gen_los: 10.6698\n",
            "Epoch 15/500\n",
            "36/36 [==============================] - 11s 300ms/step - vae_loss: 9562.4758 - disc_loss: 0.0253 - gen_los: 10.6242\n",
            "Epoch 16/500\n",
            "36/36 [==============================] - 11s 297ms/step - vae_loss: 9573.0871 - disc_loss: 0.8635 - gen_los: 2.4697\n",
            "Epoch 17/500\n",
            "36/36 [==============================] - 11s 301ms/step - vae_loss: 9609.3229 - disc_loss: 0.0013 - gen_los: 6.0977\n",
            "Epoch 18/500\n",
            "36/36 [==============================] - 11s 311ms/step - vae_loss: 9616.6878 - disc_loss: 7.5345e-05 - gen_los: 11.0832\n",
            "Epoch 19/500\n",
            "36/36 [==============================] - 11s 309ms/step - vae_loss: 9583.2158 - disc_loss: 1.1484e-05 - gen_los: 10.7236\n",
            "Epoch 20/500\n",
            "36/36 [==============================] - 11s 303ms/step - vae_loss: 9591.0020 - disc_loss: 9.9996e-06 - gen_los: 10.9341\n",
            "Epoch 21/500\n",
            "36/36 [==============================] - 11s 303ms/step - vae_loss: 9586.9379 - disc_loss: 8.1681e-06 - gen_los: 11.1276\n",
            "Epoch 22/500\n",
            "36/36 [==============================] - 11s 303ms/step - vae_loss: 9594.3649 - disc_loss: 7.3190e-06 - gen_los: 11.2349\n",
            "Epoch 23/500\n",
            "36/36 [==============================] - 11s 303ms/step - vae_loss: 9590.2626 - disc_loss: 6.4407e-06 - gen_los: 11.3702\n",
            "Epoch 24/500\n",
            "36/36 [==============================] - 11s 301ms/step - vae_loss: 9580.8044 - disc_loss: 5.8193e-06 - gen_los: 11.4849\n",
            "Epoch 25/500\n",
            "36/36 [==============================] - 11s 298ms/step - vae_loss: 9573.8883 - disc_loss: 5.3909e-06 - gen_los: 11.5561\n",
            "Epoch 26/500\n",
            "36/36 [==============================] - 11s 299ms/step - vae_loss: 9573.7614 - disc_loss: 4.8925e-06 - gen_los: 11.6902\n",
            "Epoch 27/500\n",
            "36/36 [==============================] - 11s 299ms/step - vae_loss: 9568.6460 - disc_loss: 4.3622e-06 - gen_los: 11.7940\n",
            "Epoch 28/500\n",
            "36/36 [==============================] - 11s 295ms/step - vae_loss: 9568.7517 - disc_loss: 4.5335e-06 - gen_los: 11.8365\n",
            "Epoch 29/500\n",
            "36/36 [==============================] - 11s 297ms/step - vae_loss: 9564.5818 - disc_loss: 3.7592e-06 - gen_los: 11.9793\n",
            "Epoch 30/500\n",
            "36/36 [==============================] - 11s 298ms/step - vae_loss: 9563.6442 - disc_loss: 4.0683e-06 - gen_los: 11.9221\n",
            "Epoch 31/500\n",
            "36/36 [==============================] - 11s 299ms/step - vae_loss: 9555.7208 - disc_loss: 3.6173e-06 - gen_los: 12.0865\n",
            "Epoch 32/500\n",
            "36/36 [==============================] - 11s 314ms/step - vae_loss: 9572.5366 - disc_loss: 3.4096e-06 - gen_los: 12.1949\n",
            "Epoch 33/500\n",
            "36/36 [==============================] - 11s 296ms/step - vae_loss: 9566.6348 - disc_loss: 3.4269e-06 - gen_los: 12.2040\n",
            "Epoch 34/500\n",
            "36/36 [==============================] - 11s 297ms/step - vae_loss: 9562.6891 - disc_loss: 3.3216e-06 - gen_los: 12.3334\n",
            "Epoch 35/500\n",
            "36/36 [==============================] - 11s 297ms/step - vae_loss: 9561.4023 - disc_loss: 3.9074e-06 - gen_los: 12.3389\n",
            "Epoch 36/500\n",
            "36/36 [==============================] - 11s 296ms/step - vae_loss: 9570.0192 - disc_loss: 3.4561e-06 - gen_los: 12.5264\n",
            "Epoch 37/500\n",
            "36/36 [==============================] - 11s 299ms/step - vae_loss: 9572.3799 - disc_loss: 4.1493e-06 - gen_los: 12.5884\n",
            "Epoch 38/500\n",
            "36/36 [==============================] - 11s 296ms/step - vae_loss: 9578.2595 - disc_loss: 3.0010e-06 - gen_los: 12.7258\n",
            "Epoch 39/500\n",
            "36/36 [==============================] - 11s 316ms/step - vae_loss: 9576.1227 - disc_loss: 3.2991e-06 - gen_los: 12.7698\n",
            "Epoch 40/500\n",
            "36/36 [==============================] - 11s 299ms/step - vae_loss: 9569.0004 - disc_loss: 3.0824e-06 - gen_los: 12.8162\n",
            "Epoch 41/500\n",
            "36/36 [==============================] - 11s 296ms/step - vae_loss: 9563.5719 - disc_loss: 3.6142e-06 - gen_los: 12.8493\n",
            "Epoch 42/500\n",
            "36/36 [==============================] - 11s 298ms/step - vae_loss: 9563.8268 - disc_loss: 3.6157e-06 - gen_los: 12.9349\n",
            "Epoch 43/500\n",
            "36/36 [==============================] - 11s 300ms/step - vae_loss: 9563.8095 - disc_loss: 2.6171e-06 - gen_los: 12.9693\n",
            "Epoch 44/500\n",
            "36/36 [==============================] - 11s 298ms/step - vae_loss: 9559.9365 - disc_loss: 2.6910e-06 - gen_los: 13.0455\n",
            "Epoch 45/500\n",
            "36/36 [==============================] - 11s 299ms/step - vae_loss: 9560.2949 - disc_loss: 2.3968e-06 - gen_los: 13.0813\n",
            "Epoch 46/500\n",
            "36/36 [==============================] - 11s 300ms/step - vae_loss: 9559.1550 - disc_loss: 2.1795e-06 - gen_los: 13.0892\n",
            "Epoch 47/500\n",
            "36/36 [==============================] - 11s 317ms/step - vae_loss: 9558.4005 - disc_loss: 4.1154e-06 - gen_los: 13.0758\n",
            "Epoch 48/500\n",
            "36/36 [==============================] - 11s 302ms/step - vae_loss: 9557.0777 - disc_loss: 2.5010e-06 - gen_los: 13.2581\n",
            "Epoch 49/500\n",
            "36/36 [==============================] - 11s 299ms/step - vae_loss: 9554.5897 - disc_loss: 4.0226e-06 - gen_los: 13.2378\n",
            "Epoch 50/500\n",
            "36/36 [==============================] - 11s 304ms/step - vae_loss: 9555.1218 - disc_loss: 2.7262e-06 - gen_los: 13.3596\n",
            "Epoch 51/500\n",
            "36/36 [==============================] - 11s 302ms/step - vae_loss: 9553.9649 - disc_loss: 2.3297e-06 - gen_los: 13.3682\n",
            "Epoch 52/500\n",
            "36/36 [==============================] - 11s 304ms/step - vae_loss: 9553.8552 - disc_loss: 2.7284e-06 - gen_los: 13.3495\n",
            "Epoch 53/500\n",
            "36/36 [==============================] - 11s 297ms/step - vae_loss: 9554.4815 - disc_loss: 1.9810e-06 - gen_los: 13.4271\n",
            "Epoch 54/500\n",
            "36/36 [==============================] - 11s 300ms/step - vae_loss: 9553.2672 - disc_loss: 2.0181e-06 - gen_los: 13.4240\n",
            "Epoch 55/500\n",
            "36/36 [==============================] - 11s 303ms/step - vae_loss: 9553.1727 - disc_loss: 3.6172e-06 - gen_los: 13.4190\n",
            "Epoch 56/500\n",
            "36/36 [==============================] - 11s 297ms/step - vae_loss: 9553.6073 - disc_loss: 2.4143e-06 - gen_los: 13.5993\n",
            "Epoch 57/500\n",
            "36/36 [==============================] - 11s 297ms/step - vae_loss: 9553.7252 - disc_loss: 2.0817e-06 - gen_los: 13.6032\n",
            "Epoch 58/500\n",
            "36/36 [==============================] - 11s 297ms/step - vae_loss: 9551.1258 - disc_loss: 1.7927e-06 - gen_los: 13.6095\n",
            "Epoch 59/500\n",
            "36/36 [==============================] - 11s 298ms/step - vae_loss: 9551.4463 - disc_loss: 2.2895e-06 - gen_los: 13.6098\n",
            "Epoch 60/500\n",
            "36/36 [==============================] - 11s 298ms/step - vae_loss: 9553.2691 - disc_loss: 2.1068e-06 - gen_los: 13.6552\n",
            "Epoch 61/500\n",
            "36/36 [==============================] - 11s 296ms/step - vae_loss: 9550.3950 - disc_loss: 1.9791e-06 - gen_los: 13.7234\n",
            "Epoch 62/500\n",
            "36/36 [==============================] - 11s 295ms/step - vae_loss: 9550.9951 - disc_loss: 1.7823e-06 - gen_los: 13.7256\n",
            "Epoch 63/500\n",
            "36/36 [==============================] - 11s 313ms/step - vae_loss: 9548.8921 - disc_loss: 2.2201e-06 - gen_los: 13.7635\n",
            "Epoch 64/500\n",
            "36/36 [==============================] - 11s 296ms/step - vae_loss: 9551.8482 - disc_loss: 1.5102e-06 - gen_los: 13.8378\n",
            "Epoch 65/500\n",
            "36/36 [==============================] - 11s 299ms/step - vae_loss: 9550.2261 - disc_loss: 1.9138e-06 - gen_los: 13.8221\n",
            "Epoch 66/500\n",
            "36/36 [==============================] - 11s 299ms/step - vae_loss: 9550.9676 - disc_loss: 1.4170e-06 - gen_los: 13.9301\n",
            "Epoch 67/500\n",
            "36/36 [==============================] - 11s 299ms/step - vae_loss: 9549.1303 - disc_loss: 1.4069e-06 - gen_los: 13.9141\n",
            "Epoch 68/500\n",
            "36/36 [==============================] - 11s 299ms/step - vae_loss: 9550.0452 - disc_loss: 1.5382e-06 - gen_los: 13.9203\n",
            "Epoch 69/500\n",
            "36/36 [==============================] - 11s 298ms/step - vae_loss: 9548.5199 - disc_loss: 1.5618e-06 - gen_los: 13.9770\n",
            "Epoch 70/500\n",
            "36/36 [==============================] - 11s 318ms/step - vae_loss: 9549.4262 - disc_loss: 1.3770e-06 - gen_los: 14.0082\n",
            "Epoch 71/500\n",
            "36/36 [==============================] - 11s 297ms/step - vae_loss: 9550.3250 - disc_loss: 2.0458e-06 - gen_los: 14.0116\n",
            "Epoch 72/500\n",
            "36/36 [==============================] - 11s 300ms/step - vae_loss: 9553.1737 - disc_loss: 2.4597e-06 - gen_los: 14.0693\n",
            "Epoch 73/500\n",
            "36/36 [==============================] - 11s 302ms/step - vae_loss: 9551.5617 - disc_loss: 1.4998e-06 - gen_los: 14.2997\n",
            "Epoch 74/500\n",
            "36/36 [==============================] - 11s 299ms/step - vae_loss: 9556.3528 - disc_loss: 9.6687e-07 - gen_los: 14.0986\n",
            "Epoch 75/500\n",
            "36/36 [==============================] - 11s 297ms/step - vae_loss: 9556.9371 - disc_loss: 7.0232e-07 - gen_los: 14.2560\n",
            "Epoch 76/500\n",
            "36/36 [==============================] - 11s 297ms/step - vae_loss: 9560.2229 - disc_loss: 5.3735e-07 - gen_los: 14.3824\n",
            "Epoch 77/500\n",
            "36/36 [==============================] - 11s 298ms/step - vae_loss: 9556.8345 - disc_loss: 5.1886e-07 - gen_los: 14.3360\n",
            "Epoch 78/500\n",
            "36/36 [==============================] - 11s 296ms/step - vae_loss: 9561.7097 - disc_loss: 4.2982e-07 - gen_los: 14.3072\n",
            "Epoch 79/500\n",
            "36/36 [==============================] - 11s 298ms/step - vae_loss: 9557.4363 - disc_loss: 6.2555e-07 - gen_los: 14.4354\n",
            "Epoch 80/500\n",
            "36/36 [==============================] - 11s 299ms/step - vae_loss: 9562.3980 - disc_loss: 5.2974e-07 - gen_los: 14.5315\n",
            "Epoch 81/500\n",
            "36/36 [==============================] - 11s 308ms/step - vae_loss: 9556.0790 - disc_loss: 3.3188e-07 - gen_los: 14.5192\n",
            "Epoch 82/500\n",
            "36/36 [==============================] - 11s 307ms/step - vae_loss: 9575.4670 - disc_loss: 2.8895e-07 - gen_los: 14.6151\n",
            "Epoch 83/500\n",
            "36/36 [==============================] - 11s 305ms/step - vae_loss: 9566.2250 - disc_loss: 2.7914e-07 - gen_los: 14.6172\n",
            "Epoch 84/500\n",
            "36/36 [==============================] - 11s 301ms/step - vae_loss: 9565.9485 - disc_loss: 2.5272e-07 - gen_los: 14.7713\n",
            "Epoch 85/500\n",
            "36/36 [==============================] - 11s 318ms/step - vae_loss: 9552.7382 - disc_loss: 3.1484e-07 - gen_los: 14.7414\n",
            "Epoch 86/500\n",
            "36/36 [==============================] - 11s 297ms/step - vae_loss: 9550.4060 - disc_loss: 2.7917e-07 - gen_los: 14.7734\n",
            "Epoch 87/500\n",
            "36/36 [==============================] - 11s 297ms/step - vae_loss: 9546.7460 - disc_loss: 2.2644e-07 - gen_los: 14.9300\n",
            "Epoch 88/500\n",
            "36/36 [==============================] - 11s 300ms/step - vae_loss: 9546.0179 - disc_loss: 1.8821e-07 - gen_los: 15.0706\n",
            "Epoch 89/500\n",
            "36/36 [==============================] - 11s 299ms/step - vae_loss: 9545.5004 - disc_loss: 1.8938e-07 - gen_los: 15.1649\n",
            "Epoch 90/500\n",
            "36/36 [==============================] - 11s 299ms/step - vae_loss: 9546.5900 - disc_loss: 1.6013e-07 - gen_los: 15.2646\n",
            "Epoch 91/500\n",
            "36/36 [==============================] - 11s 299ms/step - vae_loss: 9545.5342 - disc_loss: 1.5798e-07 - gen_los: 15.3977\n",
            "Epoch 92/500\n",
            "36/36 [==============================] - 11s 299ms/step - vae_loss: 9546.3502 - disc_loss: 1.4409e-07 - gen_los: 15.4916\n",
            "Epoch 93/500\n",
            "36/36 [==============================] - 11s 299ms/step - vae_loss: 9544.6953 - disc_loss: 1.1039e-07 - gen_los: 15.6545\n",
            "Epoch 94/500\n",
            "36/36 [==============================] - 11s 317ms/step - vae_loss: 9545.5751 - disc_loss: 9.5563e-08 - gen_los: 15.7953\n",
            "Epoch 95/500\n",
            "36/36 [==============================] - 11s 300ms/step - vae_loss: 9544.7741 - disc_loss: 9.3824e-08 - gen_los: 15.8902\n",
            "Epoch 96/500\n",
            "36/36 [==============================] - 11s 301ms/step - vae_loss: 9544.2600 - disc_loss: 9.6365e-08 - gen_los: 15.9873\n",
            "Epoch 97/500\n",
            "36/36 [==============================] - 11s 305ms/step - vae_loss: 9544.9767 - disc_loss: 8.2904e-08 - gen_los: 16.0354\n",
            "Epoch 98/500\n",
            "36/36 [==============================] - 11s 305ms/step - vae_loss: 9544.7523 - disc_loss: 7.4177e-08 - gen_los: 16.1657\n",
            "Epoch 99/500\n",
            "36/36 [==============================] - 11s 305ms/step - vae_loss: 9544.8713 - disc_loss: 6.3234e-08 - gen_los: 16.2207\n",
            "Epoch 100/500\n",
            "36/36 [==============================] - 11s 301ms/step - vae_loss: 9545.0662 - disc_loss: 6.4622e-08 - gen_los: 16.4014\n",
            "Epoch 101/500\n",
            "36/36 [==============================] - 11s 296ms/step - vae_loss: 9545.1493 - disc_loss: 6.1398e-08 - gen_los: 16.3965\n",
            "Epoch 102/500\n",
            "36/36 [==============================] - 11s 316ms/step - vae_loss: 9544.6007 - disc_loss: 4.4811e-08 - gen_los: 16.5861\n",
            "Epoch 103/500\n",
            "36/36 [==============================] - 11s 297ms/step - vae_loss: 9543.9301 - disc_loss: 4.2643e-08 - gen_los: 16.7453\n",
            "Epoch 104/500\n",
            "36/36 [==============================] - 11s 299ms/step - vae_loss: 9544.6163 - disc_loss: 3.9409e-08 - gen_los: 16.7635\n",
            "Epoch 105/500\n",
            "36/36 [==============================] - 11s 297ms/step - vae_loss: 9544.3746 - disc_loss: 3.4236e-08 - gen_los: 16.8293\n",
            "Epoch 106/500\n",
            "36/36 [==============================] - 11s 298ms/step - vae_loss: 9544.5722 - disc_loss: 3.0484e-08 - gen_los: 16.9308\n",
            "Epoch 107/500\n",
            "36/36 [==============================] - 11s 301ms/step - vae_loss: 9543.5354 - disc_loss: 3.2032e-08 - gen_los: 16.9396\n",
            "Epoch 108/500\n",
            "36/36 [==============================] - 11s 297ms/step - vae_loss: 9544.5974 - disc_loss: 3.6255e-08 - gen_los: 16.8588\n",
            "Epoch 109/500\n",
            "36/36 [==============================] - 11s 298ms/step - vae_loss: 9543.8091 - disc_loss: 3.6139e-08 - gen_los: 16.7987\n",
            "Epoch 110/500\n",
            "36/36 [==============================] - 11s 297ms/step - vae_loss: 9544.7468 - disc_loss: 2.8909e-08 - gen_los: 16.9526\n",
            "Epoch 111/500\n",
            "36/36 [==============================] - 11s 296ms/step - vae_loss: 9544.6164 - disc_loss: 2.5589e-08 - gen_los: 17.0298\n",
            "Epoch 112/500\n",
            "36/36 [==============================] - 11s 295ms/step - vae_loss: 9543.3928 - disc_loss: 2.4912e-08 - gen_los: 17.0152\n",
            "Epoch 113/500\n",
            "36/36 [==============================] - 11s 295ms/step - vae_loss: 9543.3492 - disc_loss: 2.2878e-08 - gen_los: 17.0493\n",
            "Epoch 114/500\n",
            "36/36 [==============================] - 11s 296ms/step - vae_loss: 9546.3370 - disc_loss: 2.5718e-08 - gen_los: 17.1360\n",
            "Epoch 115/500\n",
            "36/36 [==============================] - 11s 296ms/step - vae_loss: 9545.1963 - disc_loss: 2.5910e-08 - gen_los: 16.8914\n",
            "Epoch 116/500\n",
            "36/36 [==============================] - 11s 296ms/step - vae_loss: 9543.1612 - disc_loss: 2.2794e-08 - gen_los: 17.0765\n",
            "Epoch 117/500\n",
            "36/36 [==============================] - 11s 297ms/step - vae_loss: 9544.2677 - disc_loss: 2.1267e-08 - gen_los: 17.0991\n",
            "Epoch 118/500\n",
            "36/36 [==============================] - 11s 295ms/step - vae_loss: 9543.5250 - disc_loss: 2.4742e-08 - gen_los: 17.1319\n",
            "Epoch 119/500\n",
            "36/36 [==============================] - 11s 316ms/step - vae_loss: 9543.2587 - disc_loss: 2.6401e-08 - gen_los: 16.8590\n",
            "Epoch 120/500\n",
            "36/36 [==============================] - 11s 295ms/step - vae_loss: 9542.5379 - disc_loss: 2.0148e-08 - gen_los: 17.1547\n",
            "Epoch 121/500\n",
            "36/36 [==============================] - 11s 297ms/step - vae_loss: 9541.7305 - disc_loss: 1.8748e-08 - gen_los: 17.1888\n",
            "Epoch 122/500\n",
            "36/36 [==============================] - 11s 297ms/step - vae_loss: 9541.3154 - disc_loss: 1.8326e-08 - gen_los: 17.2004\n",
            "Epoch 123/500\n",
            "36/36 [==============================] - 11s 296ms/step - vae_loss: 9541.5579 - disc_loss: 1.7931e-08 - gen_los: 17.1916\n",
            "Epoch 124/500\n",
            "36/36 [==============================] - 11s 296ms/step - vae_loss: 9541.2455 - disc_loss: 1.7808e-08 - gen_los: 17.1936\n",
            "Epoch 125/500\n",
            "36/36 [==============================] - 11s 297ms/step - vae_loss: 9541.5979 - disc_loss: 1.7837e-08 - gen_los: 17.1957\n",
            "Epoch 126/500\n",
            "36/36 [==============================] - 11s 297ms/step - vae_loss: 9541.8267 - disc_loss: 1.9654e-08 - gen_los: 17.1296\n",
            "Epoch 127/500\n",
            "36/36 [==============================] - 11s 297ms/step - vae_loss: 9543.4272 - disc_loss: 2.1433e-08 - gen_los: 16.9345\n",
            "Epoch 128/500\n",
            "36/36 [==============================] - 11s 318ms/step - vae_loss: 9541.5330 - disc_loss: 1.8461e-08 - gen_los: 17.1931\n",
            "Epoch 129/500\n",
            "36/36 [==============================] - 11s 296ms/step - vae_loss: 9542.5336 - disc_loss: 1.8180e-08 - gen_los: 17.1639\n",
            "Epoch 130/500\n",
            "36/36 [==============================] - 11s 297ms/step - vae_loss: 9540.3432 - disc_loss: 1.7394e-08 - gen_los: 17.1839\n",
            "Epoch 131/500\n",
            "36/36 [==============================] - 11s 298ms/step - vae_loss: 9541.0911 - disc_loss: 1.6627e-08 - gen_los: 17.2584\n",
            "Epoch 132/500\n",
            "36/36 [==============================] - 11s 297ms/step - vae_loss: 9541.7828 - disc_loss: 1.8634e-08 - gen_los: 17.2075\n",
            "Epoch 133/500\n",
            "36/36 [==============================] - 11s 298ms/step - vae_loss: 9542.6109 - disc_loss: 2.2166e-08 - gen_los: 16.8692\n",
            "Epoch 134/500\n",
            "36/36 [==============================] - 11s 298ms/step - vae_loss: 9544.9736 - disc_loss: 1.8158e-08 - gen_los: 17.1846\n",
            "Epoch 135/500\n",
            "36/36 [==============================] - 11s 296ms/step - vae_loss: 9542.2017 - disc_loss: 1.6609e-08 - gen_los: 17.2641\n",
            "Epoch 136/500\n",
            "36/36 [==============================] - 11s 297ms/step - vae_loss: 9541.0368 - disc_loss: 1.6810e-08 - gen_los: 17.2456\n",
            "Epoch 137/500\n",
            "36/36 [==============================] - 11s 298ms/step - vae_loss: 9540.5565 - disc_loss: 1.5972e-08 - gen_los: 17.2632\n",
            "Epoch 138/500\n",
            "36/36 [==============================] - 11s 299ms/step - vae_loss: 9541.0284 - disc_loss: 1.6087e-08 - gen_los: 17.2709\n",
            "Epoch 139/500\n",
            "36/36 [==============================] - 11s 299ms/step - vae_loss: 9540.8411 - disc_loss: 1.5505e-08 - gen_los: 17.2708\n",
            "Epoch 140/500\n",
            "36/36 [==============================] - 11s 299ms/step - vae_loss: 9539.4330 - disc_loss: 1.5738e-08 - gen_los: 17.2728\n",
            "Epoch 141/500\n",
            "36/36 [==============================] - 11s 305ms/step - vae_loss: 9540.0294 - disc_loss: 1.5224e-08 - gen_los: 17.2702\n",
            "Epoch 142/500\n",
            "36/36 [==============================] - 11s 300ms/step - vae_loss: 9539.0574 - disc_loss: 1.5097e-08 - gen_los: 17.3185\n",
            "Epoch 143/500\n",
            "36/36 [==============================] - 11s 299ms/step - vae_loss: 9540.3509 - disc_loss: 1.5107e-08 - gen_los: 17.2714\n",
            "Epoch 144/500\n",
            "36/36 [==============================] - 11s 298ms/step - vae_loss: 9538.4790 - disc_loss: 1.4602e-08 - gen_los: 17.3270\n",
            "Epoch 145/500\n",
            "36/36 [==============================] - 11s 295ms/step - vae_loss: 9540.5798 - disc_loss: 1.5455e-08 - gen_los: 17.2457\n",
            "Epoch 146/500\n",
            "36/36 [==============================] - 11s 295ms/step - vae_loss: 9543.4286 - disc_loss: 1.4554e-08 - gen_los: 17.3252\n",
            "Epoch 147/500\n",
            "36/36 [==============================] - 11s 297ms/step - vae_loss: 9541.7211 - disc_loss: 1.5956e-08 - gen_los: 17.2072\n",
            "Epoch 148/500\n",
            "36/36 [==============================] - 11s 298ms/step - vae_loss: 9540.9205 - disc_loss: 1.4796e-08 - gen_los: 17.2769\n",
            "Epoch 149/500\n",
            "36/36 [==============================] - 11s 300ms/step - vae_loss: 9538.0404 - disc_loss: 1.5111e-08 - gen_los: 17.3013\n",
            "Epoch 150/500\n",
            "36/36 [==============================] - 11s 299ms/step - vae_loss: 9538.8917 - disc_loss: 1.4753e-08 - gen_los: 17.2817\n",
            "Epoch 151/500\n",
            "36/36 [==============================] - 11s 317ms/step - vae_loss: 9537.5608 - disc_loss: 1.5105e-08 - gen_los: 17.2956\n",
            "Epoch 152/500\n",
            "36/36 [==============================] - 11s 296ms/step - vae_loss: 9538.4593 - disc_loss: 1.5050e-08 - gen_los: 17.2688\n",
            "Epoch 153/500\n",
            "36/36 [==============================] - 11s 297ms/step - vae_loss: 9536.3039 - disc_loss: 1.4886e-08 - gen_los: 17.2922\n",
            "Epoch 154/500\n",
            "36/36 [==============================] - 11s 297ms/step - vae_loss: 9536.4323 - disc_loss: 1.4868e-08 - gen_los: 17.2918\n",
            "Epoch 155/500\n",
            "36/36 [==============================] - 11s 298ms/step - vae_loss: 9536.8076 - disc_loss: 1.4519e-08 - gen_los: 17.3007\n",
            "Epoch 156/500\n",
            "36/36 [==============================] - 11s 298ms/step - vae_loss: 9536.7696 - disc_loss: 1.4714e-08 - gen_los: 17.2950\n",
            "Epoch 157/500\n",
            "36/36 [==============================] - 11s 299ms/step - vae_loss: 9537.9816 - disc_loss: 1.4742e-08 - gen_los: 17.2796\n",
            "Epoch 158/500\n",
            "36/36 [==============================] - 12s 318ms/step - vae_loss: 9537.4315 - disc_loss: 1.4753e-08 - gen_los: 17.3026\n",
            "Epoch 159/500\n",
            "36/36 [==============================] - 11s 299ms/step - vae_loss: 9538.8324 - disc_loss: 1.4852e-08 - gen_los: 17.2544\n",
            "Epoch 160/500\n",
            "36/36 [==============================] - 11s 299ms/step - vae_loss: 9537.0104 - disc_loss: 1.4565e-08 - gen_los: 17.2966\n",
            "Epoch 161/500\n",
            "36/36 [==============================] - 11s 299ms/step - vae_loss: 9538.5631 - disc_loss: 1.4738e-08 - gen_los: 17.2842\n",
            "Epoch 162/500\n",
            "36/36 [==============================] - 11s 298ms/step - vae_loss: 9536.6582 - disc_loss: 1.4605e-08 - gen_los: 17.2924\n",
            "Epoch 163/500\n",
            "36/36 [==============================] - 11s 297ms/step - vae_loss: 9537.3259 - disc_loss: 1.4669e-08 - gen_los: 17.2936\n",
            "Epoch 164/500\n",
            "36/36 [==============================] - 11s 299ms/step - vae_loss: 9536.7714 - disc_loss: 1.4406e-08 - gen_los: 17.3062\n",
            "Epoch 165/500\n",
            "36/36 [==============================] - 11s 298ms/step - vae_loss: 9539.6858 - disc_loss: 1.4911e-08 - gen_los: 17.2986\n",
            "Epoch 166/500\n",
            "36/36 [==============================] - 11s 318ms/step - vae_loss: 9537.4534 - disc_loss: 1.5013e-08 - gen_los: 17.2587\n",
            "Epoch 167/500\n",
            "36/36 [==============================] - 11s 300ms/step - vae_loss: 9537.9942 - disc_loss: 1.5031e-08 - gen_los: 17.2906\n",
            "Epoch 168/500\n",
            "36/36 [==============================] - 11s 298ms/step - vae_loss: 9544.4604 - disc_loss: 2.9816e-08 - gen_los: 17.3063\n",
            "Epoch 169/500\n",
            "36/36 [==============================] - 11s 298ms/step - vae_loss: 9550.8436 - disc_loss: 2.3889e-08 - gen_los: 17.1600\n",
            "Epoch 170/500\n",
            "36/36 [==============================] - 11s 299ms/step - vae_loss: 9560.0700 - disc_loss: 2.0008e-08 - gen_los: 17.1913\n",
            "Epoch 171/500\n",
            "36/36 [==============================] - 11s 296ms/step - vae_loss: 9565.5759 - disc_loss: 1.5936e-08 - gen_los: 17.4470\n",
            "Epoch 172/500\n",
            "36/36 [==============================] - 11s 296ms/step - vae_loss: 9576.3848 - disc_loss: 1.4153e-08 - gen_los: 17.4680\n",
            "Epoch 173/500\n",
            "36/36 [==============================] - 11s 298ms/step - vae_loss: 9562.8147 - disc_loss: 1.2387e-08 - gen_los: 17.5937\n",
            "Epoch 174/500\n",
            "36/36 [==============================] - 11s 317ms/step - vae_loss: 9554.3195 - disc_loss: 1.3102e-08 - gen_los: 17.5026\n",
            "Epoch 175/500\n",
            "36/36 [==============================] - 11s 299ms/step - vae_loss: 9563.1602 - disc_loss: 1.3267e-08 - gen_los: 17.4866\n",
            "Epoch 176/500\n",
            "36/36 [==============================] - 11s 297ms/step - vae_loss: 9550.2388 - disc_loss: 1.2223e-08 - gen_los: 17.5354\n",
            "Epoch 177/500\n",
            "36/36 [==============================] - 11s 297ms/step - vae_loss: 9543.2699 - disc_loss: 1.3164e-08 - gen_los: 17.5008\n",
            "Epoch 178/500\n",
            "36/36 [==============================] - 11s 297ms/step - vae_loss: 9540.7714 - disc_loss: 1.2515e-08 - gen_los: 17.5047\n",
            "Epoch 179/500\n",
            "36/36 [==============================] - 11s 297ms/step - vae_loss: 9538.4430 - disc_loss: 1.2918e-08 - gen_los: 17.4735\n",
            "Epoch 180/500\n",
            "36/36 [==============================] - 11s 297ms/step - vae_loss: 9536.8719 - disc_loss: 1.2516e-08 - gen_los: 17.4887\n",
            "Epoch 181/500\n",
            "36/36 [==============================] - 11s 296ms/step - vae_loss: 9536.3992 - disc_loss: 1.2740e-08 - gen_los: 17.4713\n",
            "Epoch 182/500\n",
            "36/36 [==============================] - 11s 298ms/step - vae_loss: 9536.5143 - disc_loss: 1.2507e-08 - gen_los: 17.4747\n",
            "Epoch 183/500\n",
            "36/36 [==============================] - 11s 315ms/step - vae_loss: 9534.6471 - disc_loss: 1.2510e-08 - gen_los: 17.4719\n",
            "Epoch 184/500\n",
            "36/36 [==============================] - 11s 297ms/step - vae_loss: 9534.0574 - disc_loss: 1.2524e-08 - gen_los: 17.4646\n",
            "Epoch 185/500\n",
            "36/36 [==============================] - 11s 295ms/step - vae_loss: 9533.6600 - disc_loss: 1.2515e-08 - gen_los: 17.4645\n",
            "Epoch 186/500\n",
            "36/36 [==============================] - 11s 297ms/step - vae_loss: 9533.5825 - disc_loss: 1.2468e-08 - gen_los: 17.4657\n",
            "Epoch 187/500\n",
            "36/36 [==============================] - 11s 295ms/step - vae_loss: 9533.2105 - disc_loss: 1.2540e-08 - gen_los: 17.4573\n",
            "Epoch 188/500\n",
            "36/36 [==============================] - 11s 295ms/step - vae_loss: 9534.0210 - disc_loss: 1.2389e-08 - gen_los: 17.4667\n",
            "Epoch 189/500\n",
            "36/36 [==============================] - 11s 295ms/step - vae_loss: 9533.7245 - disc_loss: 1.2555e-08 - gen_los: 17.4499\n",
            "Epoch 190/500\n",
            "36/36 [==============================] - 11s 298ms/step - vae_loss: 9535.3481 - disc_loss: 1.2342e-08 - gen_los: 17.4663\n",
            "Epoch 191/500\n",
            "36/36 [==============================] - 11s 318ms/step - vae_loss: 9533.2469 - disc_loss: 1.2402e-08 - gen_los: 17.4580\n",
            "Epoch 192/500\n",
            "36/36 [==============================] - 11s 297ms/step - vae_loss: 9533.0223 - disc_loss: 1.2414e-08 - gen_los: 17.4509\n",
            "Epoch 193/500\n",
            "36/36 [==============================] - 11s 298ms/step - vae_loss: 9532.3005 - disc_loss: 1.2381e-08 - gen_los: 17.4615\n",
            "Epoch 194/500\n",
            "36/36 [==============================] - 11s 299ms/step - vae_loss: 9532.4634 - disc_loss: 1.2311e-08 - gen_los: 17.4615\n",
            "Epoch 195/500\n",
            "36/36 [==============================] - 11s 299ms/step - vae_loss: 9532.2239 - disc_loss: 1.2386e-08 - gen_los: 17.4598\n",
            "Epoch 196/500\n",
            "36/36 [==============================] - 11s 294ms/step - vae_loss: 9532.5176 - disc_loss: 1.2237e-08 - gen_los: 17.4742\n",
            "Epoch 197/500\n",
            "36/36 [==============================] - 11s 296ms/step - vae_loss: 9532.8270 - disc_loss: 1.2431e-08 - gen_los: 17.4495\n",
            "Epoch 198/500\n",
            "36/36 [==============================] - 11s 297ms/step - vae_loss: 9533.5462 - disc_loss: 1.2218e-08 - gen_los: 17.4710\n",
            "Epoch 199/500\n",
            "36/36 [==============================] - 11s 298ms/step - vae_loss: 9533.4638 - disc_loss: 1.2677e-08 - gen_los: 17.4556\n",
            "Epoch 200/500\n",
            "36/36 [==============================] - 11s 313ms/step - vae_loss: 9536.2100 - disc_loss: 1.2054e-08 - gen_los: 17.4836\n",
            "Epoch 201/500\n",
            "36/36 [==============================] - 11s 298ms/step - vae_loss: 9533.6722 - disc_loss: 1.2190e-08 - gen_los: 17.4742\n",
            "Epoch 202/500\n",
            "36/36 [==============================] - 11s 298ms/step - vae_loss: 9533.1286 - disc_loss: 1.2291e-08 - gen_los: 17.4538\n",
            "Epoch 203/500\n",
            "36/36 [==============================] - 11s 296ms/step - vae_loss: 9532.4840 - disc_loss: 1.2208e-08 - gen_los: 17.4762\n",
            "Epoch 204/500\n",
            "36/36 [==============================] - 11s 295ms/step - vae_loss: 9532.2583 - disc_loss: 1.2249e-08 - gen_los: 17.4618\n",
            "Epoch 205/500\n",
            "36/36 [==============================] - 11s 298ms/step - vae_loss: 9532.3752 - disc_loss: 1.2329e-08 - gen_los: 17.4725\n",
            "Epoch 206/500\n",
            "36/36 [==============================] - 11s 296ms/step - vae_loss: 9532.4684 - disc_loss: 1.2157e-08 - gen_los: 17.4767\n",
            "Epoch 207/500\n",
            "36/36 [==============================] - 11s 299ms/step - vae_loss: 9532.7619 - disc_loss: 1.2274e-08 - gen_los: 17.4761\n",
            "Epoch 208/500\n",
            "36/36 [==============================] - 11s 297ms/step - vae_loss: 9534.9422 - disc_loss: 1.2036e-08 - gen_los: 17.4756\n",
            "Epoch 209/500\n",
            "36/36 [==============================] - 11s 294ms/step - vae_loss: 9534.8634 - disc_loss: 1.1919e-08 - gen_los: 17.5085\n",
            "Epoch 210/500\n",
            "36/36 [==============================] - 11s 296ms/step - vae_loss: 9533.9997 - disc_loss: 1.2385e-08 - gen_los: 17.4428\n",
            "Epoch 211/500\n",
            "36/36 [==============================] - 11s 296ms/step - vae_loss: 9533.9086 - disc_loss: 1.2171e-08 - gen_los: 17.4650\n",
            "Epoch 212/500\n",
            "36/36 [==============================] - 11s 298ms/step - vae_loss: 9532.7715 - disc_loss: 1.2268e-08 - gen_los: 17.4594\n",
            "Epoch 213/500\n",
            "36/36 [==============================] - 11s 296ms/step - vae_loss: 9532.9046 - disc_loss: 1.2176e-08 - gen_los: 17.4712\n",
            "Epoch 214/500\n",
            "36/36 [==============================] - 11s 296ms/step - vae_loss: 9532.0199 - disc_loss: 1.2239e-08 - gen_los: 17.4711\n",
            "Epoch 215/500\n",
            "36/36 [==============================] - 11s 296ms/step - vae_loss: 9532.6025 - disc_loss: 1.2190e-08 - gen_los: 17.4711\n",
            "Epoch 216/500\n",
            "36/36 [==============================] - 11s 299ms/step - vae_loss: 9532.4284 - disc_loss: 1.2150e-08 - gen_los: 17.4785\n",
            "Epoch 217/500\n",
            "36/36 [==============================] - 11s 309ms/step - vae_loss: 9533.4352 - disc_loss: 1.2150e-08 - gen_los: 17.4628\n",
            "Epoch 218/500\n",
            "36/36 [==============================] - 11s 304ms/step - vae_loss: 9533.4579 - disc_loss: 1.1974e-08 - gen_los: 17.4856\n",
            "Epoch 219/500\n",
            "36/36 [==============================] - 11s 295ms/step - vae_loss: 9532.6797 - disc_loss: 1.2269e-08 - gen_los: 17.4674\n",
            "Epoch 220/500\n",
            "36/36 [==============================] - 11s 294ms/step - vae_loss: 9534.3777 - disc_loss: 1.1899e-08 - gen_los: 17.4935\n",
            "Epoch 221/500\n",
            "36/36 [==============================] - 11s 295ms/step - vae_loss: 9532.6419 - disc_loss: 1.2300e-08 - gen_los: 17.4746\n",
            "Epoch 222/500\n",
            "36/36 [==============================] - 11s 298ms/step - vae_loss: 9533.5234 - disc_loss: 1.1936e-08 - gen_los: 17.4841\n",
            "Epoch 223/500\n",
            "36/36 [==============================] - 11s 295ms/step - vae_loss: 9533.3405 - disc_loss: 1.2122e-08 - gen_los: 17.4793\n",
            "Epoch 224/500\n",
            "36/36 [==============================] - 11s 295ms/step - vae_loss: 9533.0004 - disc_loss: 1.2199e-08 - gen_los: 17.4664\n",
            "Epoch 225/500\n",
            "36/36 [==============================] - 11s 299ms/step - vae_loss: 9533.7731 - disc_loss: 1.2003e-08 - gen_los: 17.4736\n",
            "Epoch 226/500\n",
            "36/36 [==============================] - 11s 305ms/step - vae_loss: 9534.2895 - disc_loss: 1.2571e-08 - gen_los: 17.4715\n",
            "Epoch 227/500\n",
            "36/36 [==============================] - 11s 311ms/step - vae_loss: 9535.4446 - disc_loss: 1.2020e-08 - gen_los: 17.5043\n",
            "Epoch 228/500\n",
            "36/36 [==============================] - 11s 297ms/step - vae_loss: 9532.8083 - disc_loss: 1.2292e-08 - gen_los: 17.4756\n",
            "Epoch 229/500\n",
            "36/36 [==============================] - 11s 295ms/step - vae_loss: 9535.1827 - disc_loss: 1.2062e-08 - gen_los: 17.4565\n",
            "Epoch 230/500\n",
            "36/36 [==============================] - 11s 296ms/step - vae_loss: 9535.6309 - disc_loss: 1.2786e-08 - gen_los: 17.3795\n",
            "Epoch 231/500\n",
            "36/36 [==============================] - 11s 297ms/step - vae_loss: 9532.7050 - disc_loss: 1.2156e-08 - gen_los: 17.4643\n",
            "Epoch 232/500\n",
            "36/36 [==============================] - 11s 297ms/step - vae_loss: 9533.5098 - disc_loss: 1.2037e-08 - gen_los: 17.4913\n",
            "Epoch 233/500\n",
            "36/36 [==============================] - 11s 296ms/step - vae_loss: 9530.9701 - disc_loss: 1.2112e-08 - gen_los: 17.4788\n",
            "Epoch 234/500\n",
            "36/36 [==============================] - 11s 303ms/step - vae_loss: 9531.6133 - disc_loss: 1.2073e-08 - gen_los: 17.4779\n",
            "Epoch 235/500\n",
            "36/36 [==============================] - 11s 306ms/step - vae_loss: 9531.6844 - disc_loss: 1.2162e-08 - gen_los: 17.4846\n",
            "Epoch 236/500\n",
            "36/36 [==============================] - 11s 312ms/step - vae_loss: 9531.2938 - disc_loss: 1.2030e-08 - gen_los: 17.4633\n",
            "Epoch 237/500\n",
            "36/36 [==============================] - 11s 316ms/step - vae_loss: 9532.1651 - disc_loss: 1.2270e-08 - gen_los: 17.4707\n",
            "Epoch 238/500\n",
            "36/36 [==============================] - 11s 303ms/step - vae_loss: 9530.7036 - disc_loss: 1.2093e-08 - gen_los: 17.4578\n",
            "Epoch 239/500\n",
            "36/36 [==============================] - 11s 302ms/step - vae_loss: 9532.1274 - disc_loss: 1.2194e-08 - gen_los: 17.4650\n",
            "Epoch 240/500\n",
            "36/36 [==============================] - 11s 303ms/step - vae_loss: 9531.2920 - disc_loss: 1.2234e-08 - gen_los: 17.4602\n",
            "Epoch 241/500\n",
            "36/36 [==============================] - 11s 296ms/step - vae_loss: 9532.8563 - disc_loss: 1.2588e-08 - gen_los: 17.4394\n",
            "Epoch 242/500\n",
            "36/36 [==============================] - 11s 297ms/step - vae_loss: 9530.9265 - disc_loss: 1.6752e-08 - gen_los: 17.5025\n",
            "Epoch 243/500\n",
            "36/36 [==============================] - 11s 296ms/step - vae_loss: 9541.2706 - disc_loss: 2.1768e-08 - gen_los: 16.9004\n",
            "Epoch 244/500\n",
            "36/36 [==============================] - 11s 298ms/step - vae_loss: 9545.8295 - disc_loss: 1.6400e-08 - gen_los: 17.3768\n",
            "Epoch 245/500\n",
            "36/36 [==============================] - 11s 311ms/step - vae_loss: 9540.0708 - disc_loss: 1.4973e-08 - gen_los: 17.3774\n",
            "Epoch 246/500\n",
            "36/36 [==============================] - 11s 308ms/step - vae_loss: 9538.9827 - disc_loss: 1.5086e-08 - gen_los: 17.3776\n",
            "Epoch 247/500\n",
            "36/36 [==============================] - 11s 304ms/step - vae_loss: 9535.2303 - disc_loss: 1.4033e-08 - gen_los: 17.3618\n",
            "Epoch 248/500\n",
            "36/36 [==============================] - 11s 304ms/step - vae_loss: 9533.8003 - disc_loss: 1.4365e-08 - gen_los: 17.3632\n",
            "Epoch 249/500\n",
            "36/36 [==============================] - 11s 305ms/step - vae_loss: 9530.4347 - disc_loss: 1.3733e-08 - gen_los: 17.3829\n",
            "Epoch 250/500\n",
            "36/36 [==============================] - 11s 299ms/step - vae_loss: 9531.0325 - disc_loss: 1.3861e-08 - gen_los: 17.3987\n",
            "Epoch 251/500\n",
            "36/36 [==============================] - 11s 299ms/step - vae_loss: 9530.6669 - disc_loss: 1.3575e-08 - gen_los: 17.3893\n",
            "Epoch 252/500\n",
            "36/36 [==============================] - 11s 300ms/step - vae_loss: 9532.5231 - disc_loss: 1.3580e-08 - gen_los: 17.4098\n",
            "Epoch 253/500\n",
            "36/36 [==============================] - 12s 319ms/step - vae_loss: 9532.9953 - disc_loss: 1.3214e-08 - gen_los: 17.4136\n",
            "Epoch 254/500\n",
            "36/36 [==============================] - 11s 299ms/step - vae_loss: 9533.2077 - disc_loss: 1.3332e-08 - gen_los: 17.4124\n",
            "Epoch 255/500\n",
            "36/36 [==============================] - 11s 298ms/step - vae_loss: 9529.8221 - disc_loss: 1.3486e-08 - gen_los: 17.3895\n",
            "Epoch 256/500\n",
            "36/36 [==============================] - 11s 299ms/step - vae_loss: 9529.8358 - disc_loss: 1.3103e-08 - gen_los: 17.4111\n",
            "Epoch 257/500\n",
            "36/36 [==============================] - 11s 298ms/step - vae_loss: 9529.0407 - disc_loss: 1.3320e-08 - gen_los: 17.4092\n",
            "Epoch 258/500\n",
            "36/36 [==============================] - 11s 301ms/step - vae_loss: 9529.0706 - disc_loss: 1.3086e-08 - gen_los: 17.4141\n",
            "Epoch 259/500\n",
            "36/36 [==============================] - 11s 297ms/step - vae_loss: 9529.2691 - disc_loss: 1.3185e-08 - gen_los: 17.4045\n",
            "Epoch 260/500\n",
            "36/36 [==============================] - 11s 299ms/step - vae_loss: 9529.9047 - disc_loss: 1.3033e-08 - gen_los: 17.4103\n",
            "Epoch 261/500\n",
            "36/36 [==============================] - 11s 317ms/step - vae_loss: 9529.6459 - disc_loss: 1.3012e-08 - gen_los: 17.4100\n",
            "Epoch 262/500\n",
            "36/36 [==============================] - 11s 298ms/step - vae_loss: 9529.0821 - disc_loss: 1.3103e-08 - gen_los: 17.4078\n",
            "Epoch 263/500\n",
            "36/36 [==============================] - 11s 297ms/step - vae_loss: 9529.0681 - disc_loss: 1.2902e-08 - gen_los: 17.4211\n",
            "Epoch 264/500\n",
            "36/36 [==============================] - 11s 297ms/step - vae_loss: 9529.1149 - disc_loss: 1.2967e-08 - gen_los: 17.4201\n",
            "Epoch 265/500\n",
            "36/36 [==============================] - 11s 298ms/step - vae_loss: 9529.4583 - disc_loss: 1.2892e-08 - gen_los: 17.4161\n",
            "Epoch 266/500\n",
            "36/36 [==============================] - 11s 298ms/step - vae_loss: 9529.3540 - disc_loss: 1.2875e-08 - gen_los: 17.4290\n",
            "Epoch 267/500\n",
            "36/36 [==============================] - 11s 295ms/step - vae_loss: 9530.0762 - disc_loss: 1.2772e-08 - gen_los: 17.4290\n",
            "Epoch 268/500\n",
            "36/36 [==============================] - 11s 298ms/step - vae_loss: 9529.3271 - disc_loss: 1.2802e-08 - gen_los: 17.4360\n",
            "Epoch 269/500\n",
            "36/36 [==============================] - 11s 295ms/step - vae_loss: 9529.5883 - disc_loss: 1.2742e-08 - gen_los: 17.4206\n",
            "Epoch 270/500\n",
            "36/36 [==============================] - 11s 313ms/step - vae_loss: 9529.2513 - disc_loss: 1.2742e-08 - gen_los: 17.4458\n",
            "Epoch 271/500\n",
            "36/36 [==============================] - 11s 296ms/step - vae_loss: 9529.8108 - disc_loss: 1.2702e-08 - gen_los: 17.4357\n",
            "Epoch 272/500\n",
            "36/36 [==============================] - 11s 297ms/step - vae_loss: 9530.0705 - disc_loss: 1.2521e-08 - gen_los: 17.4543\n",
            "Epoch 273/500\n",
            "36/36 [==============================] - 11s 298ms/step - vae_loss: 9530.2641 - disc_loss: 1.2728e-08 - gen_los: 17.4382\n",
            "Epoch 274/500\n",
            "36/36 [==============================] - 11s 297ms/step - vae_loss: 9530.1133 - disc_loss: 1.2349e-08 - gen_los: 17.4689\n",
            "Epoch 275/500\n",
            "36/36 [==============================] - 11s 297ms/step - vae_loss: 9530.0655 - disc_loss: 1.2828e-08 - gen_los: 17.4373\n",
            "Epoch 276/500\n",
            "36/36 [==============================] - 11s 298ms/step - vae_loss: 9529.1593 - disc_loss: 1.2552e-08 - gen_los: 17.4556\n",
            "Epoch 277/500\n",
            "36/36 [==============================] - 11s 298ms/step - vae_loss: 9529.4008 - disc_loss: 1.2530e-08 - gen_los: 17.4585\n",
            "Epoch 278/500\n",
            "36/36 [==============================] - 11s 309ms/step - vae_loss: 9529.3152 - disc_loss: 1.2656e-08 - gen_los: 17.4462\n",
            "Epoch 279/500\n",
            "36/36 [==============================] - 11s 297ms/step - vae_loss: 9529.3422 - disc_loss: 1.2479e-08 - gen_los: 17.4677\n",
            "Epoch 280/500\n",
            "36/36 [==============================] - 11s 299ms/step - vae_loss: 9530.5771 - disc_loss: 1.2667e-08 - gen_los: 17.4431\n",
            "Epoch 281/500\n",
            "36/36 [==============================] - 11s 299ms/step - vae_loss: 9531.8327 - disc_loss: 1.2540e-08 - gen_los: 17.4877\n",
            "Epoch 282/500\n",
            "36/36 [==============================] - 11s 299ms/step - vae_loss: 9532.0657 - disc_loss: 1.2549e-08 - gen_los: 17.4538\n",
            "Epoch 283/500\n",
            "36/36 [==============================] - 11s 299ms/step - vae_loss: 9530.0837 - disc_loss: 1.2541e-08 - gen_los: 17.4558\n",
            "Epoch 284/500\n",
            "36/36 [==============================] - 11s 297ms/step - vae_loss: 9529.6031 - disc_loss: 1.2385e-08 - gen_los: 17.4709\n",
            "Epoch 285/500\n",
            "36/36 [==============================] - 11s 299ms/step - vae_loss: 9529.6138 - disc_loss: 1.2566e-08 - gen_los: 17.4702\n",
            "Epoch 286/500\n",
            "36/36 [==============================] - 11s 295ms/step - vae_loss: 9529.5557 - disc_loss: 1.2367e-08 - gen_los: 17.4852\n",
            "Epoch 287/500\n",
            "36/36 [==============================] - 11s 295ms/step - vae_loss: 9529.6987 - disc_loss: 1.2365e-08 - gen_los: 17.4853\n",
            "Epoch 288/500\n",
            "36/36 [==============================] - 11s 315ms/step - vae_loss: 9529.5826 - disc_loss: 1.2450e-08 - gen_los: 17.4685\n",
            "Epoch 289/500\n",
            "36/36 [==============================] - 11s 298ms/step - vae_loss: 9530.5694 - disc_loss: 1.2155e-08 - gen_los: 17.4930\n",
            "Epoch 290/500\n",
            "36/36 [==============================] - 11s 297ms/step - vae_loss: 9538.2001 - disc_loss: 1.3634e-08 - gen_los: 17.4806\n",
            "Epoch 291/500\n",
            "36/36 [==============================] - 11s 298ms/step - vae_loss: 9547.7825 - disc_loss: 1.1986 - gen_los: 17.0527\n",
            "Epoch 292/500\n",
            "36/36 [==============================] - 11s 296ms/step - vae_loss: 9540.7759 - disc_loss: 0.6981 - gen_los: 0.0212\n",
            "Epoch 293/500\n",
            "36/36 [==============================] - 11s 295ms/step - vae_loss: 9530.0864 - disc_loss: 0.6931 - gen_los: 0.0024\n",
            "Epoch 294/500\n",
            "36/36 [==============================] - 11s 296ms/step - vae_loss: 9561.0141 - disc_loss: 0.6931 - gen_los: 0.0018\n",
            "Epoch 295/500\n",
            "36/36 [==============================] - 11s 314ms/step - vae_loss: 9553.9546 - disc_loss: 0.6931 - gen_los: 0.0013\n",
            "Epoch 296/500\n",
            "36/36 [==============================] - 11s 295ms/step - vae_loss: 9547.4045 - disc_loss: 0.6931 - gen_los: 0.0010\n",
            "Epoch 297/500\n",
            "36/36 [==============================] - 11s 297ms/step - vae_loss: 9546.6091 - disc_loss: 0.6931 - gen_los: 7.5860e-04\n",
            "Epoch 298/500\n",
            "36/36 [==============================] - 11s 296ms/step - vae_loss: 9536.4611 - disc_loss: 0.6931 - gen_los: 5.6539e-04\n",
            "Epoch 299/500\n",
            "36/36 [==============================] - 11s 298ms/step - vae_loss: 9537.2612 - disc_loss: 0.6931 - gen_los: 4.1894e-04\n",
            "Epoch 300/500\n",
            "36/36 [==============================] - 11s 303ms/step - vae_loss: 9530.3326 - disc_loss: 0.6931 - gen_los: 3.0862e-04\n",
            "Epoch 301/500\n",
            "36/36 [==============================] - 11s 299ms/step - vae_loss: 9522.6793 - disc_loss: 0.6931 - gen_los: 2.2595e-04\n",
            "Epoch 302/500\n",
            "36/36 [==============================] - 11s 301ms/step - vae_loss: 9518.4783 - disc_loss: 0.6931 - gen_los: 1.6438e-04\n",
            "Epoch 303/500\n",
            "36/36 [==============================] - 11s 296ms/step - vae_loss: 9517.5880 - disc_loss: 0.6931 - gen_los: 1.1894e-04\n",
            "Epoch 304/500\n",
            "36/36 [==============================] - 11s 296ms/step - vae_loss: 9516.0881 - disc_loss: 0.6931 - gen_los: 1.0000e-04\n",
            "Epoch 305/500\n",
            "36/36 [==============================] - 11s 313ms/step - vae_loss: 9515.8855 - disc_loss: 0.6931 - gen_los: 1.0000e-04\n",
            "Epoch 306/500\n",
            "36/36 [==============================] - 11s 296ms/step - vae_loss: 9514.9837 - disc_loss: 0.6931 - gen_los: 1.0000e-04\n",
            "Epoch 307/500\n",
            "36/36 [==============================] - 11s 296ms/step - vae_loss: 9515.4048 - disc_loss: 0.6931 - gen_los: 1.0000e-04\n",
            "Epoch 308/500\n",
            "36/36 [==============================] - 11s 293ms/step - vae_loss: 9514.3660 - disc_loss: 0.6931 - gen_los: 1.0000e-04\n",
            "Epoch 309/500\n",
            "36/36 [==============================] - 11s 304ms/step - vae_loss: 9514.3903 - disc_loss: 0.6931 - gen_los: 1.0000e-04\n",
            "Epoch 310/500\n",
            "36/36 [==============================] - 11s 299ms/step - vae_loss: 9513.7205 - disc_loss: 0.6931 - gen_los: 1.0000e-04\n",
            "Epoch 311/500\n",
            "36/36 [==============================] - 11s 300ms/step - vae_loss: 9514.2157 - disc_loss: 0.6931 - gen_los: 1.0000e-04\n",
            "Epoch 312/500\n",
            "36/36 [==============================] - 11s 298ms/step - vae_loss: 9513.2461 - disc_loss: 0.6931 - gen_los: 1.0000e-04\n",
            "Epoch 313/500\n",
            "36/36 [==============================] - 11s 301ms/step - vae_loss: 9513.6490 - disc_loss: 0.6931 - gen_los: 1.0000e-04\n",
            "Epoch 314/500\n",
            "36/36 [==============================] - 11s 315ms/step - vae_loss: 9513.0329 - disc_loss: 0.6931 - gen_los: 1.0000e-04\n",
            "Epoch 315/500\n",
            "36/36 [==============================] - 11s 297ms/step - vae_loss: 9513.3709 - disc_loss: 0.6931 - gen_los: 1.0000e-04\n",
            "Epoch 316/500\n",
            "36/36 [==============================] - 11s 298ms/step - vae_loss: 9512.6899 - disc_loss: 0.6931 - gen_los: 1.0000e-04\n",
            "Epoch 317/500\n",
            "36/36 [==============================] - 11s 295ms/step - vae_loss: 9513.4853 - disc_loss: 0.6931 - gen_los: 1.0000e-04\n",
            "Epoch 318/500\n",
            "36/36 [==============================] - 11s 298ms/step - vae_loss: 9512.4926 - disc_loss: 0.6931 - gen_los: 1.0000e-04\n",
            "Epoch 319/500\n",
            "36/36 [==============================] - 11s 295ms/step - vae_loss: 9513.0662 - disc_loss: 0.6931 - gen_los: 1.0000e-04\n",
            "Epoch 320/500\n",
            "36/36 [==============================] - 11s 296ms/step - vae_loss: 9512.1129 - disc_loss: 0.6931 - gen_los: 1.0000e-04\n",
            "Epoch 321/500\n",
            "36/36 [==============================] - 11s 296ms/step - vae_loss: 9512.6148 - disc_loss: 0.6931 - gen_los: 1.0000e-04\n",
            "Epoch 322/500\n",
            "36/36 [==============================] - 11s 295ms/step - vae_loss: 9512.0389 - disc_loss: 0.6931 - gen_los: 1.0000e-04\n",
            "Epoch 323/500\n",
            "36/36 [==============================] - 11s 313ms/step - vae_loss: 9512.5126 - disc_loss: 0.6931 - gen_los: 1.0000e-04\n",
            "Epoch 324/500\n",
            "36/36 [==============================] - 11s 299ms/step - vae_loss: 9512.0379 - disc_loss: 0.6931 - gen_los: 1.0000e-04\n",
            "Epoch 325/500\n",
            "36/36 [==============================] - 11s 294ms/step - vae_loss: 9512.4523 - disc_loss: 0.6931 - gen_los: 1.0000e-04\n",
            "Epoch 326/500\n",
            "36/36 [==============================] - 11s 297ms/step - vae_loss: 9511.9570 - disc_loss: 0.6931 - gen_los: 1.0000e-04\n",
            "Epoch 327/500\n",
            "36/36 [==============================] - 11s 299ms/step - vae_loss: 9512.4041 - disc_loss: 0.6931 - gen_los: 1.0000e-04\n",
            "Epoch 328/500\n",
            "36/36 [==============================] - 11s 300ms/step - vae_loss: 9511.9333 - disc_loss: 0.6931 - gen_los: 1.0000e-04\n",
            "Epoch 329/500\n",
            "36/36 [==============================] - 11s 304ms/step - vae_loss: 9512.0818 - disc_loss: 0.6931 - gen_los: 1.0000e-04\n",
            "Epoch 330/500\n",
            "36/36 [==============================] - 11s 301ms/step - vae_loss: 9511.4889 - disc_loss: 0.6931 - gen_los: 1.0000e-04\n",
            "Epoch 331/500\n",
            "36/36 [==============================] - 11s 297ms/step - vae_loss: 9511.5734 - disc_loss: 0.6931 - gen_los: 1.0000e-04\n",
            "Epoch 332/500\n",
            "36/36 [==============================] - 11s 316ms/step - vae_loss: 9511.1399 - disc_loss: 0.6931 - gen_los: 1.0000e-04\n",
            "Epoch 333/500\n",
            "36/36 [==============================] - 11s 296ms/step - vae_loss: 9511.4387 - disc_loss: 0.6931 - gen_los: 1.0000e-04\n",
            "Epoch 334/500\n",
            "36/36 [==============================] - 11s 295ms/step - vae_loss: 9511.1178 - disc_loss: 0.6931 - gen_los: 1.0000e-04\n",
            "Epoch 335/500\n",
            "36/36 [==============================] - 11s 301ms/step - vae_loss: 9511.2146 - disc_loss: 0.6931 - gen_los: 1.0000e-04\n",
            "Epoch 336/500\n",
            "36/36 [==============================] - 11s 300ms/step - vae_loss: 9510.9274 - disc_loss: 0.6931 - gen_los: 1.0000e-04\n",
            "Epoch 337/500\n",
            "36/36 [==============================] - 11s 305ms/step - vae_loss: 9511.4013 - disc_loss: 0.6931 - gen_los: 1.0000e-04\n",
            "Epoch 338/500\n",
            "36/36 [==============================] - 11s 298ms/step - vae_loss: 9510.8487 - disc_loss: 0.6931 - gen_los: 1.0000e-04\n",
            "Epoch 339/500\n",
            "36/36 [==============================] - 11s 298ms/step - vae_loss: 9511.6115 - disc_loss: 0.6931 - gen_los: 1.0000e-04\n",
            "Epoch 340/500\n",
            "36/36 [==============================] - 11s 304ms/step - vae_loss: 9511.4689 - disc_loss: 0.6931 - gen_los: 1.0000e-04\n",
            "Epoch 341/500\n",
            "36/36 [==============================] - 11s 296ms/step - vae_loss: 9512.0143 - disc_loss: 0.6931 - gen_los: 1.0000e-04\n",
            "Epoch 342/500\n",
            "36/36 [==============================] - 11s 299ms/step - vae_loss: 9511.7795 - disc_loss: 0.6931 - gen_los: 1.0000e-04\n",
            "Epoch 343/500\n",
            "36/36 [==============================] - 11s 302ms/step - vae_loss: 9511.8945 - disc_loss: 0.6931 - gen_los: 1.0000e-04\n",
            "Epoch 344/500\n",
            "36/36 [==============================] - 11s 300ms/step - vae_loss: 9511.5337 - disc_loss: 0.6931 - gen_los: 1.0000e-04\n",
            "Epoch 345/500\n",
            "36/36 [==============================] - 11s 300ms/step - vae_loss: 9511.4518 - disc_loss: 0.6931 - gen_los: 1.0000e-04\n",
            "Epoch 346/500\n",
            "36/36 [==============================] - 11s 301ms/step - vae_loss: 9511.6171 - disc_loss: 0.6931 - gen_los: 1.0000e-04\n",
            "Epoch 347/500\n",
            "36/36 [==============================] - 11s 298ms/step - vae_loss: 9511.8175 - disc_loss: 0.6931 - gen_los: 1.0000e-04\n",
            "Epoch 348/500\n",
            "36/36 [==============================] - 11s 299ms/step - vae_loss: 9512.1296 - disc_loss: 0.6931 - gen_los: 1.0000e-04\n",
            "Epoch 349/500\n",
            "36/36 [==============================] - 11s 297ms/step - vae_loss: 9512.2318 - disc_loss: 0.6931 - gen_los: 1.0000e-04\n",
            "Epoch 350/500\n",
            "36/36 [==============================] - 11s 301ms/step - vae_loss: 9512.0083 - disc_loss: 0.6931 - gen_los: 1.0000e-04\n",
            "Epoch 351/500\n",
            "36/36 [==============================] - 11s 300ms/step - vae_loss: 9512.0553 - disc_loss: 0.6931 - gen_los: 1.0000e-04\n",
            "Epoch 352/500\n",
            "36/36 [==============================] - 11s 298ms/step - vae_loss: 9512.0631 - disc_loss: 0.6931 - gen_los: 1.0000e-04\n",
            "Epoch 353/500\n",
            "17/36 [=============>................] - ETA: 5s - vae_loss: 9521.3401 - disc_loss: 0.6931 - gen_los: 1.0000e-04"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#  **Results Analyse**"
      ],
      "metadata": {
        "papermill": {
          "duration": 1.012978,
          "end_time": "2021-11-08T23:20:35.412725",
          "exception": false,
          "start_time": "2021-11-08T23:20:34.399747",
          "status": "completed"
        },
        "tags": [],
        "id": "I4FlWPKcT5eu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "history_frame = pd.DataFrame(history.history)\n",
        "history_frame.loc[:, ['vae_loss']].plot()"
      ],
      "metadata": {
        "papermill": {
          "duration": 1.263609,
          "end_time": "2021-11-08T23:20:37.729311",
          "exception": false,
          "start_time": "2021-11-08T23:20:36.465702",
          "status": "completed"
        },
        "tags": [],
        "trusted": true,
        "id": "7M0A2E2BT5eu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Latent space"
      ],
      "metadata": {
        "id": "_KuXMECpT5eu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "_ ,digit_size = image_size\n",
        "scale = 1\n",
        "def plot_latent_space(vae, n=8, figsize=15):\n",
        "    # display a n*n 2D manifold of digits\n",
        "    figure = np.zeros((digit_size * n, digit_size * n,3))\n",
        "    # linearly spaced coordinates corresponding to the 2D plot\n",
        "    # of digit classes in the latent space\n",
        "    grid_x = np.linspace(-scale, scale, n)\n",
        "    grid_y = np.linspace(-scale, scale, n)[::-1]\n",
        "\n",
        "    for i, yi in enumerate(grid_y):\n",
        "        for j, xi in enumerate(grid_x):\n",
        "            z_sample = np.array([[2*random.random()-1 for i in range(latent_dim)]])\n",
        "            x_decoded = vae.decoder.predict(z_sample)\n",
        "            digit = x_decoded[0].reshape(digit_size, digit_size,3)\n",
        "            figure[\n",
        "                i * digit_size : (i + 1) * digit_size,\n",
        "                j * digit_size : (j + 1) * digit_size,\n",
        "            ] = digit\n",
        "\n",
        "    plt.figure(figsize=(figsize, figsize))\n",
        "    start_range = digit_size // 2\n",
        "    end_range = n * digit_size + start_range\n",
        "    pixel_range = np.arange(start_range, end_range, digit_size)\n",
        "    sample_range_x = np.round(grid_x, 1)\n",
        "    sample_range_y = np.round(grid_y, 1)\n",
        "    plt.xticks(pixel_range, sample_range_x)\n",
        "    plt.yticks(pixel_range, sample_range_y)\n",
        "    plt.xlabel(\"z[0]\")\n",
        "    plt.ylabel(\"z[1]\")\n",
        "    plt.imshow(figure)\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "plot_latent_space(model)"
      ],
      "metadata": {
        "trusted": true,
        "id": "p5Txb6qQT5eu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# On training set"
      ],
      "metadata": {
        "papermill": {
          "duration": 1.278153,
          "end_time": "2021-11-08T23:20:40.025694",
          "exception": false,
          "start_time": "2021-11-08T23:20:38.747541",
          "status": "completed"
        },
        "tags": [],
        "id": "JdWtNI4ET5ev"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "digit_size, _ = image_size\n",
        "n = 4\n",
        "figure = np.zeros((digit_size*3, digit_size * n,3))\n",
        "img = list(ds)[0]\n",
        "\n",
        "for i in range(n):\n",
        "    _,b_img = model(img)\n",
        "    a = list(b_img)[i]\n",
        "    figure[\n",
        "                 0*digit_size :  digit_size,\n",
        "                i * digit_size :  (i+1)* digit_size,\n",
        "            ] = a\n",
        "    figure[\n",
        "                 1*digit_size :  2*digit_size,\n",
        "                i * digit_size :  (i+1)* digit_size,\n",
        "            ] = list(img)[i]\n",
        "    \n",
        "    figure[\n",
        "                 2*digit_size :  3*digit_size,\n",
        "                i * digit_size :  (i+1)* digit_size,\n",
        "            ] = (a-list(img)[i])*10\n",
        "    \n",
        "figsize = 5   \n",
        "plt.figure(figsize=(figsize*n, figsize*3))\n",
        "plt.imshow(figure)\n",
        "plt.show()"
      ],
      "metadata": {
        "papermill": {
          "duration": 1.996591,
          "end_time": "2021-11-08T23:20:43.028058",
          "exception": false,
          "start_time": "2021-11-08T23:20:41.031467",
          "status": "completed"
        },
        "tags": [],
        "trusted": true,
        "id": "3GCygaIJT5ev"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# On test set"
      ],
      "metadata": {
        "papermill": {
          "duration": 1.060937,
          "end_time": "2021-11-08T23:20:45.109664",
          "exception": false,
          "start_time": "2021-11-08T23:20:44.048727",
          "status": "completed"
        },
        "tags": [],
        "id": "h0H0stG5T5ev"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "n = 2\n",
        "figure = np.zeros((digit_size*3, digit_size * n,3))\n",
        "img = list(ds_a)[0]\n",
        "for i in range(n):\n",
        "    _,b_img = model(img)\n",
        "    a = list(b_img)[i]\n",
        "    figure[\n",
        "                 0*digit_size :  digit_size,\n",
        "                i * digit_size :  (i+1)* digit_size,\n",
        "            ] = a\n",
        "    figure[\n",
        "                 1*digit_size :  2*digit_size,\n",
        "                i * digit_size :  (i+1)* digit_size,\n",
        "            ] = list(img)[i]\n",
        "    \n",
        "    figure[\n",
        "                 2*digit_size :  3*digit_size,\n",
        "                i * digit_size :  (i+1)* digit_size,\n",
        "            ] = (a-list(img)[i])*10\n",
        "\n",
        "figsize = 10  \n",
        "plt.figure(figsize=(figsize*n, figsize*3))\n",
        "plt.imshow(figure)\n",
        "plt.show()"
      ],
      "metadata": {
        "trusted": true,
        "id": "2UECFllwT5ev"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}